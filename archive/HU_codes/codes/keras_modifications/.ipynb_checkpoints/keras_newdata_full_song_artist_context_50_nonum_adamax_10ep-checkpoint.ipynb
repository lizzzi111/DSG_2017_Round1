{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl\n",
      "Collecting imbalanced-learn (from imblearn)\n",
      "  Downloading imbalanced-learn-0.2.1.tar.gz (90kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 660kB/s \n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.17.0 in /anaconda/lib/python3.5/site-packages (from imbalanced-learn->imblearn)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /anaconda/lib/python3.5/site-packages (from imbalanced-learn->imblearn)\n",
      "Requirement already satisfied: scikit-learn>=0.17.1 in /anaconda/lib/python3.5/site-packages (from imbalanced-learn->imblearn)\n",
      "Building wheels for collected packages: imbalanced-learn\n",
      "  Running setup.py bdist_wheel for imbalanced-learn ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\n",
      "\u001b[?25h  Stored in directory: /Users/Kozodoi/Library/Caches/pip/wheels/b8/20/bd/0b775f7e5d413ac72562b1a5126598bcb6e0eae10da659be9f\n",
      "Successfully built imbalanced-learn\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.2.1 imblearn-0.0\n"
     ]
    }
   ],
   "source": [
    "# libraries\n",
    "#!pip install rpy2\n",
    "#!pip install pandas\n",
    "#!pip install keras\n",
    "#!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# libraries\n",
    "import rpy2.robjects as robjects\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Embedding, concatenate, Flatten, Dropout, Reshape\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7578752, 55)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data\n",
    "path = \"/Users/Kozodoi/Documents/Competitions/DSG_2017/\"\n",
    "data = pd.read_csv(path + \"data/data_flow.csv\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add observation index\n",
    "data[\"row_index\"] = data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (7519013, 56)\n",
      "test: (39821, 56)\n",
      "known: (7558834, 56)\n",
      "unknown: (19918, 56)\n"
     ]
    }
   ],
   "source": [
    "# data partitioning\n",
    "tr = data.query(\"dataset == 'train'\")\n",
    "ts = data.query(\"dataset == 'test'\")\n",
    "kn = data.query(\"dataset != 'unknown'\")\n",
    "un = data.query(\"dataset == 'unknown'\")\n",
    "\n",
    "# print data sizes\n",
    "print(\"train: \"   + str(tr.shape))\n",
    "print(\"test: \"    + str(ts.shape))\n",
    "print(\"known: \"   + str(kn.shape))\n",
    "print(\"unknown: \" + str(un.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['user_id', 'media_id', 'artist_id', 'genre_id', 'context_type',\n",
      "       'media_duration', 'listen_type', 'user_gender', 'user_age',\n",
      "       'is_listened', 'sample_id', 'dataset', 'session_id',\n",
      "       'song_session_position', 'first_flow', 'time_diff_release_listen',\n",
      "       'release_year', 'is_listened_lag1', 'is_listened_lag2',\n",
      "       'user_skip_ratio_last5', 'genre_equal_last_song',\n",
      "       'artist_equal_last_song', 'album_equal_last_song', 'genre_plays',\n",
      "       'genre_skips', 'artist_plays', 'artist_skips', 'album_plays',\n",
      "       'album_skips', 'song_plays', 'song_skips', 'user_ratio_flow',\n",
      "       'user_ratio_full', 'genre_ratio', 'artist_ratio', 'song_ratio',\n",
      "       'user_genre_ratio', 'user_artist_ratio', 'user_song_ratio',\n",
      "       'platform_name', 'platform_family', 'hour_of_day1', 'hour_of_day2',\n",
      "       'hour_of_day3', 'hour_of_day4', 'hour_of_day5', 'hour_of_day6',\n",
      "       'hour_of_day7', 'hour_of_day8', 'weekdayMon', 'weekdaySat',\n",
      "       'weekdaySun', 'weekdayThu', 'weekdayTue', 'weekdayWed', 'row_index'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# List numeric features used as predictors\n",
    "print(data.columns)\n",
    "numVars = [\"user_ratio_flow\", \"user_ratio_full\", \"listen_type\", \"first_flow\",\n",
    "           \"song_plays\", \"artist_plays\", \"platform_name1\", \"platform_name2\",\n",
    "           \"song_skips\", \"artist_skips\", \"song_session_position\", \"time_diff\"] \n",
    "\n",
    "# Create the data input matrix that can be passed to the keras model\n",
    "tr_data = tr[[column for column in tr.columns if column in numVars]].as_matrix()\n",
    "ts_data = ts[[column for column in ts.columns if column in numVars]].as_matrix()\n",
    "kn_data = kn[[column for column in kn.columns if column in numVars]].as_matrix()\n",
    "un_data = un[[column for column in un.columns if column in numVars]].as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. MODELING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. INITIALIZING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create an input layer with embeddings\n",
    "user_in    = Input(shape = (1,), dtype = 'int64',   name = \"user_in\")\n",
    "song_in    = Input(shape = (1,), dtype = 'int64',   name = \"song_in\")\n",
    "artist_in  = Input(shape = (1,), dtype = 'int64',   name = \"artist_in\")\n",
    "context_in = Input(shape = (1,), dtype = 'int64',   name = \"context_in\")\n",
    "\n",
    "# Create an input layer with numeric features\n",
    "data_in = Input(shape = (tr_data.shape[1],), name = \"data_in\")\n",
    "\n",
    "# Counting number of unique ID values\n",
    "n_users   = tr.user_id.nunique()\n",
    "n_songs   = tr.media_id.nunique()\n",
    "n_artists = tr.artist_id.nunique()\n",
    "n_context = tr.context_type.nunique()\n",
    "\n",
    "# Create an embedding assigning k latent factors to each ID\n",
    "u = Embedding(n_users,   50, input_length = 1, embeddings_regularizer = l2(1e-5))(user_in)\n",
    "s = Embedding(n_songs,   50, input_length = 1, embeddings_regularizer = l2(1e-5))(song_in)\n",
    "a = Embedding(n_artists, 50, input_length = 1, embeddings_regularizer = l2(1e-5))(artist_in)\n",
    "c = Embedding(n_context, 50, input_length = 1, embeddings_regularizer = l2(1e-5))(context_in)\n",
    "\n",
    "# Layer with embeddings\n",
    "embedding_input = concatenate([u, s, a, c])\n",
    "embedding_input = Flatten()(embedding_input)\n",
    "embedding_dense = Dense(128, activation = \"relu\")(embedding_input)\n",
    "x = Dropout(0.5)(embedding_dense)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(64, activation='relu')(x) \n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(1, activation = \"sigmoid\")(x)\n",
    "\n",
    "# Specify the model that we want to use\n",
    "model = Model([user_in, song_in, artist_in, context_in], output)\n",
    "model.compile(optimizer = \"adamax\", loss = \"binary_crossentropy\", metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. FIRST STAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7519013 samples, validate on 39821 samples\n",
      "Epoch 1/10\n",
      "7519013/7519013 [==============================] - 166s - loss: 0.5966 - acc: 0.7222 - val_loss: 0.6870 - val_acc: 0.6076\n",
      "Epoch 2/10\n",
      "7519013/7519013 [==============================] - 163s - loss: 0.5278 - acc: 0.7597 - val_loss: 0.6679 - val_acc: 0.6110\n",
      "Epoch 3/10\n",
      "7519013/7519013 [==============================] - 165s - loss: 0.5126 - acc: 0.7650 - val_loss: 0.6519 - val_acc: 0.6344\n",
      "Epoch 4/10\n",
      "7519013/7519013 [==============================] - 154s - loss: 0.5017 - acc: 0.7689 - val_loss: 0.6359 - val_acc: 0.6636\n",
      "Epoch 5/10\n",
      "7519013/7519013 [==============================] - 153s - loss: 0.4929 - acc: 0.7725 - val_loss: 0.6225 - val_acc: 0.6772\n",
      "Epoch 6/10\n",
      "7519013/7519013 [==============================] - 156s - loss: 0.4853 - acc: 0.7760 - val_loss: 0.6191 - val_acc: 0.6792\n",
      "Epoch 7/10\n",
      "7519013/7519013 [==============================] - 153s - loss: 0.4786 - acc: 0.7792 - val_loss: 0.6247 - val_acc: 0.6783\n",
      "Epoch 8/10\n",
      "7519013/7519013 [==============================] - 155s - loss: 0.4729 - acc: 0.7821 - val_loss: 0.6337 - val_acc: 0.6792\n",
      "Epoch 9/10\n",
      "7519013/7519013 [==============================] - 155s - loss: 0.4681 - acc: 0.7845 - val_loss: 0.6422 - val_acc: 0.6778\n",
      "Epoch 10/10\n",
      "7519013/7519013 [==============================] - 155s - loss: 0.4636 - acc: 0.7869 - val_loss: 0.6470 - val_acc: 0.6786\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1285fecc0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the estimations on training data\n",
    "model.fit([tr.user_id, tr.media_id, tr.artist_id, tr.context_type], tr.is_listened, \n",
    "validation_data = ([ts.user_id, ts.media_id, ts.artist_id, ts.context_type], ts.is_listened),\n",
    "batch_size = int(len(tr)/100), epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_index</th>\n",
       "      <th>is_listened</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5989</th>\n",
       "      <td>5989</td>\n",
       "      <td>0.983996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6053</th>\n",
       "      <td>6053</td>\n",
       "      <td>0.981035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6296</th>\n",
       "      <td>6296</td>\n",
       "      <td>0.995374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11840</th>\n",
       "      <td>11840</td>\n",
       "      <td>0.989487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11910</th>\n",
       "      <td>11910</td>\n",
       "      <td>0.999499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       row_index  is_listened\n",
       "5989        5989     0.983996\n",
       "6053        6053     0.981035\n",
       "6296        6296     0.995374\n",
       "11840      11840     0.989487\n",
       "11910      11910     0.999499"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict validation data\n",
    "pred = pd.DataFrame()\n",
    "pred[\"row_index\"] = ts.row_index\n",
    "pred[\"is_listened\"] = model.predict([ts.user_id, ts.media_id, ts.artist_id, ts.context_type])\n",
    "pred.to_csv(path + \"pred_valid/keras_newdata_full_song_artist_context_50_nonum_adamax_10ep.csv\", index = False)\n",
    "pred.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72209150152645885"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# computing AUC\n",
    "metrics.roc_auc_score(ts.is_listened, pred.is_listened)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. SECOND STAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7558834/7558834 [==============================] - 158s - loss: 0.4609 - acc: 0.7883   \n",
      "Epoch 2/10\n",
      "7558834/7558834 [==============================] - 155s - loss: 0.4574 - acc: 0.7902   \n",
      "Epoch 3/10\n",
      "7558834/7558834 [==============================] - 155s - loss: 0.4541 - acc: 0.7920   \n",
      "Epoch 4/10\n",
      "7558834/7558834 [==============================] - 154s - loss: 0.4510 - acc: 0.7935   \n",
      "Epoch 5/10\n",
      "7558834/7558834 [==============================] - 152s - loss: 0.4484 - acc: 0.7949   \n",
      "Epoch 6/10\n",
      "7558834/7558834 [==============================] - 152s - loss: 0.4458 - acc: 0.7964   \n",
      "Epoch 7/10\n",
      "7558834/7558834 [==============================] - 152s - loss: 0.4433 - acc: 0.7976   \n",
      "Epoch 8/10\n",
      "7558834/7558834 [==============================] - 152s - loss: 0.4413 - acc: 0.7988   \n",
      "Epoch 9/10\n",
      "7558834/7558834 [==============================] - 153s - loss: 0.4391 - acc: 0.7998   \n",
      "Epoch 10/10\n",
      "7558834/7558834 [==============================] - 153s - loss: 0.4371 - acc: 0.8009   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x128b0b828>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the estimations on full known data\n",
    "model.fit([kn.user_id, kn.media_id, kn.artist_id, kn.context_type], kn.is_listened,\n",
    "batch_size = int(kn.shape[0]/100), epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>is_listened</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7551765</th>\n",
       "      <td>0</td>\n",
       "      <td>0.999753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6913499</th>\n",
       "      <td>1</td>\n",
       "      <td>0.817787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6529339</th>\n",
       "      <td>2</td>\n",
       "      <td>0.851174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5409309</th>\n",
       "      <td>3</td>\n",
       "      <td>0.666113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6218646</th>\n",
       "      <td>4</td>\n",
       "      <td>0.815577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sample_id  is_listened\n",
       "7551765          0     0.999753\n",
       "6913499          1     0.817787\n",
       "6529339          2     0.851174\n",
       "5409309          3     0.666113\n",
       "6218646          4     0.815577"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict unknown data\n",
    "pred = pd.DataFrame()\n",
    "pred[\"sample_id\"] = un.sample_id.astype(int)\n",
    "pred[\"is_listened\"] = model.predict([un.user_id, un.media_id, un.artist_id, un.context_type])\n",
    "pred = pred.sort_values(\"sample_id\")\n",
    "pred.to_csv(path + \"pred_unknown/keras_newdata_full_song_artist_context_50_nonum_adamax_10ep.csv\", index = False)\n",
    "pred.head(5)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
