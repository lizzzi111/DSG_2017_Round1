{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl\n",
      "Collecting imbalanced-learn (from imblearn)\n",
      "  Downloading imbalanced-learn-0.2.1.tar.gz (90kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 660kB/s \n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.17.0 in /anaconda/lib/python3.5/site-packages (from imbalanced-learn->imblearn)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /anaconda/lib/python3.5/site-packages (from imbalanced-learn->imblearn)\n",
      "Requirement already satisfied: scikit-learn>=0.17.1 in /anaconda/lib/python3.5/site-packages (from imbalanced-learn->imblearn)\n",
      "Building wheels for collected packages: imbalanced-learn\n",
      "  Running setup.py bdist_wheel for imbalanced-learn ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \bdone\n",
      "\u001b[?25h  Stored in directory: /Users/Kozodoi/Library/Caches/pip/wheels/b8/20/bd/0b775f7e5d413ac72562b1a5126598bcb6e0eae10da659be9f\n",
      "Successfully built imbalanced-learn\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.2.1 imblearn-0.0\n"
     ]
    }
   ],
   "source": [
    "# libraries\n",
    "#!pip install rpy2\n",
    "#!pip install pandas\n",
    "#!pip install keras\n",
    "#!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# libraries\n",
    "import rpy2.robjects as robjects\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Embedding, concatenate, Flatten, Dropout, Reshape\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the data\n",
    "path = \"/Users/Kozodoi/Documents/Competitions/DSG_2017/\"\n",
    "known   = pd.read_csv(path + \"data/train.csv\")\n",
    "unknown = pd.read_csv(path + \"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2319611, 15)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep only Flow songs in the data\n",
    "# this proves to predict better, but some information is lost\n",
    "known = known.query(\"listen_type == 1\")\n",
    "known.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(805378, 15)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# limiting the maximal number of songs to 100 - works bad\n",
    "#known = known.groupby([\"user_id\"]).tail(100)\n",
    "#known.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "# Create a placeholder for the IDs new in the test data\n",
    "newUsers   = list(unknown.user_id[~unknown.user_id.isin(known.user_id)])       + list(known.user_id.value_counts().keys()[known.user_id.value_counts()     == 1])\n",
    "newSongs   = list(unknown.media_id[~unknown.media_id.isin(known.media_id)])    + list(known.media_id.value_counts().keys()[known.media_id.value_counts()   == 1])[-1000:]\n",
    "newArtists = list(unknown.artist_id[~unknown.artist_id.isin(known.artist_id)]) + list(known.artist_id.value_counts().keys()[known.artist_id.value_counts() == 1])[-1000:]\n",
    "newGenres  = list(unknown.genre_id[~unknown.genre_id.isin(known.genre_id)])    + list(known.genre_id.value_counts().keys()[known.genre_id.value_counts()   == 1])[-1000:]\n",
    "newAlbums  = list(unknown.album_id[~unknown.album_id.isin(known.album_id)])    + list(known.album_id.value_counts().keys()[known.album_id.value_counts() == 1])[-1000:]\n",
    "newContext = list(unknown.context_type[~unknown.context_type.isin(known.context_type)]) + list(known.context_type.value_counts().keys()[known.context_type.value_counts() == 1])[-1000:]\n",
    "\n",
    "# In particular, assign IDs from 0 to N for users and songs\n",
    "# Use enumerate() to create a list of the new and original IDs\n",
    "users   = list(enumerate([i for i in known.user_id.unique()   if i not in newUsers]))\n",
    "songs   = list(enumerate([i for i in known.media_id.unique()  if i not in newSongs]))\n",
    "artists = list(enumerate([i for i in known.artist_id.unique() if i not in newArtists]))\n",
    "genres  = list(enumerate([i for i in known.genre_id.unique()  if i not in newGenres]))\n",
    "albums  = list(enumerate([i for i in known.album_id.unique()  if i not in newAlbums]))\n",
    "context = list(enumerate([i for i in known.context_type.unique() if i not in newContext]))\n",
    "\n",
    "# Create a dictionary with old IDs to new IDs\n",
    "userid2idx    = {o:i for i,o in users}\n",
    "songid2idx    = {o:i for i,o in songs}\n",
    "artistid2idx  = {o:i for i,o in artists}\n",
    "genreid2idx   = {o:i for i,o in genres}\n",
    "albumid2idx   = {o:i for i,o in albums}\n",
    "contextid2idx = {o:i for i,o in context}\n",
    "\n",
    "# Update with new/rare entries\n",
    "userid2idx.update({o:(max(userid2idx.values())+1)       for o in newUsers})\n",
    "songid2idx.update({o:(max(songid2idx.values())+1)       for o in newSongs})\n",
    "artistid2idx.update({o:(max(artistid2idx.values())+1)   for o in newArtists})\n",
    "genreid2idx.update({o:(max(genreid2idx.values())+1)     for o in newGenres})\n",
    "albumid2idx.update({o:(max(albumid2idx.values())+1)     for o in newAlbums})\n",
    "contextid2idx.update({o:(max(contextid2idx.values())+1) for o in newContext})\n",
    "\n",
    "# Create id variable with the new IDs (known)\n",
    "known['userIdx']    = known.user_id.apply(lambda x:       userid2idx[x])\n",
    "known['songIdx']    = known.media_id.apply(lambda x:      songid2idx[x])\n",
    "known['artistIdx']  = known.artist_id.apply(lambda x:     artistid2idx[x])\n",
    "known['genreIdx']   = known.genre_id.apply(lambda x:      genreid2idx[x])\n",
    "known['albumIdx']   = known.album_id.apply(lambda x:      albumid2idx[x])\n",
    "known['contextIdx'] = known.context_type.apply(lambda x:  contextid2idx[x])\n",
    "\n",
    "# Create id variable with the new IDs (unknown)\n",
    "unknown['userIdx']    = unknown.user_id.apply(lambda x:      userid2idx[x])\n",
    "unknown['songIdx']    = unknown.media_id.apply(lambda x:     songid2idx[x])\n",
    "unknown['artistIdx']  = unknown.artist_id.apply(lambda x:    artistid2idx[x])\n",
    "unknown['genreIdx']   = unknown.genre_id.apply(lambda x:     genreid2idx[x])\n",
    "unknown['albumIdx']   = unknown.album_id.apply(lambda x:     albumid2idx[x])\n",
    "unknown['contextIdx'] = unknown.context_type.apply(lambda x: contextid2idx[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# partition train/test data: last 3 songs per user go to validation (stage 1)\n",
    "# model predicts better if trained on full known sample without validation (stage 2)\n",
    "ts = known.groupby([\"userIdx\"]).tail(3)\n",
    "tr = known.groupby([\"userIdx\"], group_keys=False).apply(lambda x: x[:-3])\n",
    "\n",
    "# move songs that appear only in ts to tr\n",
    "strayObs = ts.songIdx.isin(tr.songIdx) & ts.userIdx.isin(tr.userIdx) & ts.artistIdx.isin(tr.artistIdx) & ts.genreIdx.isin(tr.genreIdx) & ts.albumIdx.isin(tr.albumIdx) & ts.contextIdx.isin(tr.contextIdx)\n",
    "tr = tr.append(ts[~strayObs])\n",
    "ts = ts[strayObs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# saving the data samples\n",
    "tr.to_csv(path + \"data/tr_100.csv\", index = False)\n",
    "ts.to_csv(path + \"data/ts_100.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. MODELING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. INITIALIZING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create an input layer with one row of IDs\n",
    "user_in    = Input(shape = (1,), dtype = 'int64',   name = \"user_in\")\n",
    "song_in    = Input(shape = (1,), dtype = 'int64',   name = \"song_in\")\n",
    "artist_in  = Input(shape = (1,), dtype = 'int64',   name = \"artist_in\")\n",
    "genre_in   = Input(shape = (1,), dtype = 'int64',   name = \"genre_in\")\n",
    "album_in   = Input(shape = (1,), dtype = 'int64',   name = \"album_in\")\n",
    "context_in = Input(shape = (1,), dtype = 'int64',   name = \"context_in\")\n",
    "num_in     = Input(shape = (1,), dtype = 'float32', name = \"num_in\")\n",
    "\n",
    "# Reshaping numeric features\n",
    "n = Reshape((1,1))(num_in)\n",
    "\n",
    "# Create an embedding assigning k latent factors to each ID\n",
    "# These will be optimized\n",
    "# A regulariztaion is added to avoid very large weights\n",
    "n_users   = tr.userIdx.nunique()\n",
    "n_songs   = tr.songIdx.nunique()\n",
    "n_artists = tr.artistIdx.nunique()\n",
    "n_genres  = tr.genreIdx.nunique()\n",
    "n_albums  = tr.albumIdx.nunique()\n",
    "n_context = tr.contextIdx.nunique()\n",
    "\n",
    "# Embeddings creation\n",
    "u = Embedding(n_users,   50, input_length=1, embeddings_regularizer=l2(1e-5))(user_in)\n",
    "s = Embedding(n_songs,   50, input_length=1, embeddings_regularizer=l2(1e-5))(song_in)\n",
    "a = Embedding(n_artists, 50, input_length=1, embeddings_regularizer=l2(1e-5))(artist_in)\n",
    "g = Embedding(n_genres,  50, input_length=1, embeddings_regularizer=l2(1e-5))(genre_in)\n",
    "l = Embedding(n_albums,  50, input_length=1, embeddings_regularizer=l2(1e-5))(album_in)\n",
    "c = Embedding(n_context, 50, input_length=1, embeddings_regularizer=l2(1e-5))(context_in)\n",
    "\n",
    "# Specify what to do with the layers\n",
    "#x = concatenate([u, s, a, g, l, c, n]) # with one numeric feature\n",
    "x = concatenate([u, s, a, g, c])        # without numeric features\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(64, activation='relu')(x) \n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1, activation = \"sigmoid\")(x)\n",
    "\n",
    "# Then we specify the model that we want to use\n",
    "#model = Model([user_in, song_in, artist_in, genre_in, album_in, context_in, num_in], x) # with one numeric feature\n",
    "model = Model([user_in, song_in, artist_in, genre_in, context_in], x)                    # without numeric features\n",
    "model.compile(Adam(0.001), loss = \"binary_crossentropy\", metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. FIRST STAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 767272 samples, validate on 38106 samples\n",
      "Epoch 1/10\n",
      "767272/767272 [==============================] - 54s - loss: 0.6404 - acc: 0.6481 - val_loss: 0.6840 - val_acc: 0.5665\n",
      "Epoch 2/10\n",
      "767272/767272 [==============================] - 49s - loss: 0.5149 - acc: 0.7603 - val_loss: 0.6630 - val_acc: 0.5819\n",
      "Epoch 3/10\n",
      "767272/767272 [==============================] - 46s - loss: 0.4909 - acc: 0.7743 - val_loss: 0.6375 - val_acc: 0.6493\n",
      "Epoch 4/10\n",
      "767272/767272 [==============================] - 50s - loss: 0.4717 - acc: 0.7846 - val_loss: 0.6023 - val_acc: 0.6942\n",
      "Epoch 5/10\n",
      "767272/767272 [==============================] - 51s - loss: 0.4557 - acc: 0.7934 - val_loss: 0.5708 - val_acc: 0.7201\n",
      "Epoch 6/10\n",
      "767272/767272 [==============================] - 48s - loss: 0.4416 - acc: 0.8015 - val_loss: 0.5625 - val_acc: 0.7340\n",
      "Epoch 7/10\n",
      "767272/767272 [==============================] - 48s - loss: 0.4296 - acc: 0.8077 - val_loss: 0.5721 - val_acc: 0.7366\n",
      "Epoch 8/10\n",
      "767272/767272 [==============================] - 48s - loss: 0.4191 - acc: 0.8145 - val_loss: 0.6019 - val_acc: 0.7378\n",
      "Epoch 9/10\n",
      "767272/767272 [==============================] - 51s - loss: 0.4079 - acc: 0.8205 - val_loss: 0.6247 - val_acc: 0.7362\n",
      "Epoch 10/10\n",
      "767272/767272 [==============================] - 47s - loss: 0.3986 - acc: 0.8251 - val_loss: 0.6432 - val_acc: 0.7331\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x122e580f0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the estimations on training data\n",
    "model.fit([tr.userIdx, tr.songIdx, tr.artistIdx, tr.genreIdx, tr.contextIdx], tr.is_listened, \n",
    "validation_data = ([ts.userIdx, ts.songIdx, ts.artistIdx, ts.genreIdx, ts.contextIdx], ts.is_listened),\n",
    "batch_size = int(len(tr)/100), epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict validation data\n",
    "pred = pd.DataFrame()\n",
    "pred[\"user_id\"]  = ts.user_id\n",
    "pred[\"media_id\"] = ts.media_id\n",
    "pred[\"is_listened\"] = model.predict([ts.userIdx, ts.songIdx, ts.artistIdx, ts.genreIdx, ts.contextIdx])\n",
    "pred.to_csv(path + \"data/deep_128_64_flow_cont.csv\", index = False)\n",
    "pred.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. SECOND STAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "805378/805378 [==============================] - 54s - loss: 0.6408 - acc: 0.6526    \n",
      "Epoch 2/10\n",
      "805378/805378 [==============================] - 54s - loss: 0.5167 - acc: 0.7587    \n",
      "Epoch 3/10\n",
      "805378/805378 [==============================] - 55s - loss: 0.4932 - acc: 0.7725    \n",
      "Epoch 4/10\n",
      "805378/805378 [==============================] - 50s - loss: 0.4763 - acc: 0.7826    \n",
      "Epoch 5/10\n",
      "805378/805378 [==============================] - 51s - loss: 0.4612 - acc: 0.7915    \n",
      "Epoch 6/10\n",
      "805378/805378 [==============================] - 51s - loss: 0.4467 - acc: 0.8000    \n",
      "Epoch 7/10\n",
      "805378/805378 [==============================] - 52s - loss: 0.4351 - acc: 0.8060    \n",
      "Epoch 8/10\n",
      "805378/805378 [==============================] - 47s - loss: 0.4256 - acc: 0.8116    \n",
      "Epoch 9/10\n",
      "805378/805378 [==============================] - 47s - loss: 0.4157 - acc: 0.8166    \n",
      "Epoch 10/10\n",
      "805378/805378 [==============================] - 51s - loss: 0.4076 - acc: 0.8214    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13ebb1f98>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the estimations on full known data\n",
    "model.fit([known.userIdx, known.songIdx, known.artistIdx, known.genreIdx, known.contextIdx], known.is_listened,\n",
    "batch_size = int(known.shape[0]/100), epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>is_listened</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.999752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.295713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.491120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.631600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.814451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_id  is_listened\n",
       "0          0     0.999752\n",
       "1          1     0.295713\n",
       "2          2     0.491120\n",
       "3          3     0.631600\n",
       "4          4     0.814451"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict unknown data\n",
    "pred = pd.DataFrame()\n",
    "pred[\"sample_id\"] = unknown.sample_id\n",
    "pred[\"is_listened\"] = model.predict([unknown.userIdx, unknown.songIdx, unknown.artistIdx, unknown.genreIdx, unknown.contextIdx])\n",
    "pred.to_csv(path + \"submissions/deep_128_64_flow_cont.csv\", index = False)\n",
    "pred.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. ENSEMBLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loading naive submission\n",
    "naive = pd.read_csv(path + \"submissions/naive_ratio_user.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>is_listened</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.999876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.534862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.685319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.618228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.853127</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_id  is_listened\n",
       "0          0     0.999876\n",
       "1          1     0.534862\n",
       "2          2     0.685319\n",
       "3          3     0.618228\n",
       "4          4     0.853127"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combining predictions\n",
    "pred_mean = pd.DataFrame()\n",
    "pred_mean[\"sample_id\"] = unknown.sample_id\n",
    "pred_mean[\"is_listened\"] = 0.5*pred[\"is_listened\"] + 0.5*naive[\"is_listened\"]\n",
    "pred_mean.to_csv(path + \"submissions/deep_128_64_flow_cont_plus_ratio_user_0_5.csv\", index = False)\n",
    "pred_mean.head(5)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
