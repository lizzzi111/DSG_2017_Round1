{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rpy2\n",
      "  Downloading rpy2-2.8.5.tar.gz (184kB)\n",
      "\u001b[K    100% |████████████████████████████████| 184kB 518kB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /anaconda/lib/python3.5/site-packages (from rpy2)\n",
      "Building wheels for collected packages: rpy2\n",
      "  Running setup.py bdist_wheel for rpy2 ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\n",
      "\u001b[?25h  Stored in directory: /Users/Kozodoi/Library/Caches/pip/wheels/23/9e/ee/0e5f6a00aafef9935d40ebf7657278220139f0101321e30d07\n",
      "Successfully built rpy2\n",
      "Installing collected packages: rpy2\n",
      "Successfully installed rpy2-2.8.5\n"
     ]
    }
   ],
   "source": [
    "# libraries\n",
    "#!pip install rpy2\n",
    "#!pip install pandas\n",
    "#!pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# libraries\n",
    "#import rpy2.robjects as robjects\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Embedding, concatenate, Flatten, Dropout, Reshape\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7578752, 36)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data\n",
    "path = \"/Users/Kozodoi/Documents/Competitions/DSG_2017/\"\n",
    "#path = \"/Users/maj/Dropbox/DSG17/DSG_2017/\"\n",
    "data = pd.read_csv(path + \"data/data_full.csv\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2339528, 36)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep only Flow songs in the data\n",
    "# this proves to predict better, but some information is lost\n",
    "data = data.query(\"listen_type == 1\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2319611, 36)\n",
      "(19917, 36)\n"
     ]
    }
   ],
   "source": [
    "# data partitioning\n",
    "known   = data.query(\"dataset != 'unknown'\")\n",
    "unknown = data.query(\"dataset == 'unknown'\")\n",
    "print(known.shape)\n",
    "print(unknown.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "# Create a placeholder for the IDs new in the test data\n",
    "newUsers   = list(unknown.user_id[~unknown.user_id.isin(known.user_id)])       + list(known.user_id.value_counts().keys()[known.user_id.value_counts()     == 1])\n",
    "newSongs   = list(unknown.media_id[~unknown.media_id.isin(known.media_id)])    + list(known.media_id.value_counts().keys()[known.media_id.value_counts()   == 1])[-1000:]\n",
    "newArtists = list(unknown.artist_id[~unknown.artist_id.isin(known.artist_id)]) + list(known.artist_id.value_counts().keys()[known.artist_id.value_counts() == 1])[-1000:]\n",
    "newGenres  = list(unknown.genre_id[~unknown.genre_id.isin(known.genre_id)])    + list(known.genre_id.value_counts().keys()[known.genre_id.value_counts()   == 1])[-1000:]\n",
    "\n",
    "# In particular, assign IDs from 0 to N for users and songs\n",
    "# Use enumerate() to create a list of the new and original IDs\n",
    "users   = list(enumerate([i for i in known.user_id.unique()   if i not in newUsers]))\n",
    "songs   = list(enumerate([i for i in known.media_id.unique()  if i not in newSongs]))\n",
    "artists = list(enumerate([i for i in known.artist_id.unique() if i not in newArtists]))\n",
    "genres  = list(enumerate([i for i in known.genre_id.unique()  if i not in newGenres]))\n",
    "\n",
    "# Create a dictionary with old IDs to new IDs\n",
    "userid2idx   = {o:i for i,o in users}\n",
    "songid2idx   = {o:i for i,o in songs}\n",
    "artistid2idx = {o:i for i,o in artists}\n",
    "genreid2idx  = {o:i for i,o in genres}\n",
    "\n",
    "# Update with new/rare entries\n",
    "userid2idx.update({o:(max(userid2idx.values())+1)     for o in newUsers})\n",
    "songid2idx.update({o:(max(songid2idx.values())+1)     for o in newSongs})\n",
    "artistid2idx.update({o:(max(artistid2idx.values())+1) for o in newArtists})\n",
    "genreid2idx.update({o:(max(genreid2idx.values())+1)   for o in newGenres})\n",
    "\n",
    "# Create id variable with the new IDs\n",
    "pd.options.mode.chained_assignment = None\n",
    "known['userIdx']   = known.user_id.apply(lambda x:       userid2idx[x])\n",
    "known['songIdx']   = known.media_id.apply(lambda x:      songid2idx[x])\n",
    "known['artistIdx'] = known.artist_id.apply(lambda x:     artistid2idx[x])\n",
    "known['genreIdx']  = known.genre_id.apply(lambda x:      genreid2idx[x])\n",
    "unknown['userIdx']   = unknown.user_id.apply(lambda x:   userid2idx[x])\n",
    "unknown['songIdx']   = unknown.media_id.apply(lambda x:  songid2idx[x])\n",
    "unknown['artistIdx'] = unknown.artist_id.apply(lambda x: artistid2idx[x])\n",
    "unknown['genreIdx']  = unknown.genre_id.apply(lambda x:  genreid2idx[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2265441, 40)\n",
      "(54170, 40)\n"
     ]
    }
   ],
   "source": [
    "# partition train/test data\n",
    "#ts = known.groupby([\"userIdx\"]).tail(3)\n",
    "#tr = known.groupby([\"userIdx\"], group_keys=False).apply(lambda x: x[:-3])\n",
    "\n",
    "# partition train/test data\n",
    "tr = known.query(\"dataset == 'train'\")\n",
    "ts = known.query(\"dataset == 'test'\")\n",
    "\n",
    "# move songs that appear only in ts to tr\n",
    "strayObs = ts.songIdx.isin(tr.songIdx) & ts.userIdx.isin(tr.userIdx) & ts.artistIdx.isin(tr.artistIdx) & ts.genreIdx.isin(tr.genreIdx)\n",
    "tr = tr.append(ts[~strayObs])\n",
    "ts = ts[strayObs]\n",
    "\n",
    "# checking data sizes\n",
    "print(tr.shape)\n",
    "print(ts.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create an input layer with one row of IDs\n",
    "user_in   = Input(shape = (1,), dtype='int64',   name = \"user_in\")\n",
    "song_in   = Input(shape = (1,), dtype='int64',   name = \"song_in\")\n",
    "artist_in = Input(shape = (1,), dtype='int64',   name = \"artist_in\")\n",
    "genre_in  = Input(shape = (1,), dtype='int64',   name = \"genre_in\")\n",
    "data_in   = Input(shape = (1,), dtype='float32', name = \"data_in\")\n",
    "\n",
    "# reshaping real-valued features\n",
    "d = Reshape((1,1))(data_in)\n",
    "\n",
    "# Create an embedding assigning k latent factors to each ID\n",
    "# These will be optimized\n",
    "# A regulariztaion is added to avoid very large weights\n",
    "n_users   = tr.userIdx.nunique()\n",
    "n_songs   = tr.songIdx.nunique()\n",
    "n_artists = tr.artistIdx.nunique()\n",
    "n_genres  = tr.genreIdx.nunique()\n",
    "u = Embedding(n_users,   50, input_length=1, embeddings_regularizer=l2(1e-5))(user_in)\n",
    "s = Embedding(n_songs,   50, input_length=1, embeddings_regularizer=l2(1e-5))(song_in)\n",
    "a = Embedding(n_artists, 50, input_length=1, embeddings_regularizer=l2(1e-5))(artist_in)\n",
    "g = Embedding(n_genres,  50, input_length=1, embeddings_regularizer=l2(1e-5))(genre_in)\n",
    "\n",
    "# Specify what to do with the layers\n",
    "# We want to multiply them into a 'rating' matrix\n",
    "x = concatenate([u, s, a, g, d])\n",
    "x = Flatten()(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x)\n",
    "#x = Dropout(0.5)(Dense(128, activation='relu')(x))\n",
    "#x = BatchNormalization()(x)\n",
    "x = Dense(64, activation='relu')(x) \n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1, activation = \"sigmoid\")(x)\n",
    "#x = merge([x, ub], mode = 'sum')\n",
    "#x = merge([x, sb], mode = 'sum') # Can this be included in the line above?\n",
    "\n",
    "# Then we specify the model that we want to use\n",
    "model = Model([user_in, song_in, artist_in, genre_in, data_in], x) # \n",
    "model.compile(Adam(0.001), loss=\"binary_crossentropy\", metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2265441 samples, validate on 54170 samples\n",
      "Epoch 1/10\n",
      "2265441/2265441 [==============================] - 64s - loss: 0.5801 - acc: 0.7209 - val_loss: 0.6455 - val_acc: 0.6518\n",
      "Epoch 2/10\n",
      "2265441/2265441 [==============================] - 62s - loss: 0.5038 - acc: 0.7653 - val_loss: 0.6258 - val_acc: 0.6586\n",
      "Epoch 3/10\n",
      "2265441/2265441 [==============================] - 62s - loss: 0.4874 - acc: 0.7731 - val_loss: 0.6069 - val_acc: 0.6852\n",
      "Epoch 4/10\n",
      "2265441/2265441 [==============================] - 62s - loss: 0.4772 - acc: 0.7783 - val_loss: 0.5858 - val_acc: 0.7107\n",
      "Epoch 5/10\n",
      "2265441/2265441 [==============================] - 66s - loss: 0.4694 - acc: 0.7825 - val_loss: 0.5652 - val_acc: 0.7260\n",
      "Epoch 6/10\n",
      "2265441/2265441 [==============================] - 71s - loss: 0.4631 - acc: 0.7861 - val_loss: 0.5613 - val_acc: 0.7283\n",
      "Epoch 7/10\n",
      "2265441/2265441 [==============================] - 70s - loss: 0.4572 - acc: 0.7894 - val_loss: 0.5740 - val_acc: 0.7242\n",
      "Epoch 8/10\n",
      "2265441/2265441 [==============================] - 63s - loss: 0.4519 - acc: 0.7927 - val_loss: 0.5923 - val_acc: 0.7188\n",
      "Epoch 9/10\n",
      "2265441/2265441 [==============================] - 66s - loss: 0.4470 - acc: 0.7956 - val_loss: 0.6060 - val_acc: 0.7170\n",
      "Epoch 10/10\n",
      "2265441/2265441 [==============================] - 66s - loss: 0.4422 - acc: 0.7985 - val_loss: 0.6206 - val_acc: 0.7144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1550bfcc0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the estimations\n",
    "model.fit([tr.userIdx, tr.songIdx, tr.artistIdx, tr.genreIdx, \n",
    "           tr.user_ratio_full], tr.is_listened,\n",
    "validation_data = ([ts.userIdx, ts.songIdx, ts.artistIdx, ts.genreIdx,\n",
    "                   ts.user_ratio_full], ts.is_listened),\n",
    "batch_size = 22655, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>is_listened</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.981744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.783598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.759315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.388151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.930634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_id  is_listened\n",
       "0          0     0.981744\n",
       "1          1     0.783598\n",
       "2          2     0.759315\n",
       "3          3     0.388151\n",
       "4          4     0.930634"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict on unlabelled set\n",
    "pred = pd.DataFrame()\n",
    "pred[\"sample_id\"] = unknown.sample_id\n",
    "pred[\"is_listened\"] = model.predict([unknown.userIdx, unknown.songIdx, unknown.artistIdx, unknown.genreIdx])\n",
    "pred.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>is_listened</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.990872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.778805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.819416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.496504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.911219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sample_id  is_listened\n",
       "0          0     0.990872\n",
       "1          1     0.778805\n",
       "2          2     0.819416\n",
       "3          3     0.496504\n",
       "4          4     0.911219"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding naive submission\n",
    "naive = pd.read_csv(path + \"submissions/naive_ratio_user.csv\")\n",
    "pred_mean = pred\n",
    "pred_mean[\"is_listened\"] = (pred[\"is_listened\"] + naive[\"is_listened\"])/2\n",
    "pred_mean.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# saving submissions\n",
    "pred.to_csv(path + \"submissions/deep_128_64_flow.csv\", index = False)\n",
    "pred.to_csv(path + \"submissions/deep_128_64_flow_plus_ratio_user.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
