{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# libraries\n",
    "#!pip install rpy2\n",
    "#!pip install pandas\n",
    "#!pip install keras\n",
    "#!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "#import rpy2.robjects as robjects\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Embedding, concatenate, Flatten, Dropout, Reshape, dot, add\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7578752, 75)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data\n",
    "path = \"/Users/maj/Dropbox/DSG17/DSG_2017/\"\n",
    "data = pd.read_csv(path + \"data/data_full.csv\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add observation index\n",
    "data[\"row_index\"] = data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (7519013, 75)\n",
      "test: (39821, 75)\n",
      "known: (7558834, 75)\n",
      "unknown: (19918, 75)\n"
     ]
    }
   ],
   "source": [
    "# data partitioning\n",
    "tr = data.query(\"dataset == 'train'\")\n",
    "ts = data.query(\"dataset == 'test'\")\n",
    "kn = data.query(\"dataset != 'unknown'\")\n",
    "un = data.query(\"dataset == 'unknown'\")\n",
    "\n",
    "# print data sizes\n",
    "print(\"train: \"   + str(tr.shape))\n",
    "print(\"test: \"    + str(ts.shape))\n",
    "print(\"known: \"   + str(kn.shape))\n",
    "print(\"unknown: \" + str(un.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['media_id', 'user_id', 'context_type', 'artist_id', 'genre_id',\n",
      "       'album_id', 'media_duration', 'listen_type', 'user_gender', 'user_age',\n",
      "       'is_listened', 'sample_id', 'dataset', 'row_index', 'song_rank',\n",
      "       'song_bpm', 'song_position', 'song_lyrics_explicit', 'song_gain',\n",
      "       'album_fans', 'favorite_artist', 'favorite_album', 'radio_selecter',\n",
      "       'session_id', 'time_lag_lag1', 'time_lag_lag2', 'song_session_position',\n",
      "       'first_flow', 'time_diff_release_listen', 'release_year',\n",
      "       'is_listened_lag1', 'is_listened_lag2', 'user_skip_ratio_last3',\n",
      "       'user_skip_ratio_last5', 'user_skip_ratio_last10',\n",
      "       'context_type_same_as_lag', 'genre_equal_last_song',\n",
      "       'artist_equal_last_song', 'album_equal_last_song', 'genre_plays',\n",
      "       'genre_skips', 'artist_plays', 'artist_skips', 'album_plays',\n",
      "       'album_skips', 'song_plays', 'song_skips', 'user_ratio_flow',\n",
      "       'user_ratio_full', 'genre_ratio', 'artist_ratio', 'song_ratio',\n",
      "       'context_ratio', 'user_genre_ratio', 'user_artist_ratio',\n",
      "       'user_song_ratio', 'user_context_ratio', 'platform_name',\n",
      "       'platform_family', 'hour_of_day1', 'hour_of_day2', 'hour_of_day3',\n",
      "       'hour_of_day4', 'hour_of_day5', 'hour_of_day6', 'hour_of_day7',\n",
      "       'hour_of_day8', 'weekdayMon', 'weekdaySat', 'weekdaySun', 'weekdayThu',\n",
      "       'weekdayTue', 'weekdayWed', 'user_bias', 'song_bias'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# List numeric features used as predictors\n",
    "print(data.columns)\n",
    "numVars = [\"user_ratio_flow\", \"user_ratio_full\", \"listen_type\", \"first_flow\",\n",
    "           \"song_plays\", \"artist_plays\", \"platform_name1\", \"platform_name2\",\n",
    "           \"song_skips\", \"artist_skips\", \"song_session_position\", \"time_diff\"] \n",
    "\n",
    "# Create the data input matrix that can be passed to the keras model\n",
    "tr_data = tr[[column for column in tr.columns if column in numVars]].as_matrix()\n",
    "ts_data = ts[[column for column in ts.columns if column in numVars]].as_matrix()\n",
    "kn_data = kn[[column for column in kn.columns if column in numVars]].as_matrix()\n",
    "un_data = un[[column for column in un.columns if column in numVars]].as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. MODELING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. INITIALIZING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create an input layer with embeddings\n",
    "user_in    = Input(shape = (1,), dtype = 'int64',   name = \"user_in\")\n",
    "song_in    = Input(shape = (1,), dtype = 'int64',   name = \"song_in\")\n",
    "artist_in  = Input(shape = (1,), dtype = 'int64',   name = \"artist_in\")\n",
    "context_in = Input(shape = (1,), dtype = 'int64',   name = \"context_in\")\n",
    "\n",
    "# Create an input layer with numeric features\n",
    "data_in = Input(shape = (tr_data.shape[1],), name = \"data_in\")\n",
    "\n",
    "# Counting number of unique ID values\n",
    "n_users   = tr.user_id.nunique()\n",
    "n_songs   = tr.media_id.nunique()\n",
    "n_artists = tr.artist_id.nunique()\n",
    "n_context = tr.context_type.nunique()\n",
    "\n",
    "# Create an embedding assigning k latent factors to each ID\n",
    "u = Embedding(n_users,   50, input_length = 1, embeddings_regularizer = l2(1e-5))(user_in)\n",
    "s = Embedding(n_songs,   50, input_length = 1, embeddings_regularizer = l2(1e-5))(song_in)\n",
    "a = Embedding(n_artists, 50, input_length = 1, embeddings_regularizer = l2(1e-5))(artist_in)\n",
    "c = Embedding(n_context, 50, input_length = 1, embeddings_regularizer = l2(1e-5))(context_in)\n",
    "\n",
    "# Also create 'biases', i.e. a user and song specific value that is added\n",
    "ub = Flatten()(Embedding(n_users, 1, input_length = 1)(user_in))\n",
    "sb = Flatten()(Embedding(n_songs, 1, input_length = 1)(song_in))\n",
    "\n",
    "# Layer with embeddings\n",
    "x = dot([u, s], axes = 2)\n",
    "x = Flatten()(x)\n",
    "x = add([x, ub])\n",
    "x = add([x, sb])\n",
    "output = Dense(1, activation = \"sigmoid\")(x)\n",
    "\n",
    "# Specify the model that we want to use\n",
    "model = Model([user_in, song_in], output)\n",
    "model.compile(optimizer = \"Adagrad\", loss = \"binary_crossentropy\", metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19505\n"
     ]
    }
   ],
   "source": [
    "print(n_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. FIRST STAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7519013 samples, validate on 39821 samples\n",
      "Epoch 1/5\n",
      "7519013/7519013 [==============================] - 43s - loss: 0.4936 - acc: 0.7618 - val_loss: 0.6328 - val_acc: 0.6543\n",
      "Epoch 2/5\n",
      "7519013/7519013 [==============================] - 39s - loss: 0.4930 - acc: 0.7620 - val_loss: 0.6335 - val_acc: 0.6539\n",
      "Epoch 3/5\n",
      "7519013/7519013 [==============================] - 40s - loss: 0.4924 - acc: 0.7622 - val_loss: 0.6340 - val_acc: 0.6540\n",
      "Epoch 4/5\n",
      "7519013/7519013 [==============================] - 41s - loss: 0.4919 - acc: 0.7624 - val_loss: 0.6344 - val_acc: 0.6537\n",
      "Epoch 5/5\n",
      "7519013/7519013 [==============================] - 42s - loss: 0.4914 - acc: 0.7626 - val_loss: 0.6348 - val_acc: 0.6536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cd3712e8>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the estimations on training data\n",
    "model.fit([tr.user_id, tr.media_id], tr.is_listened, \n",
    "validation_data = ([ts.user_id, ts.media_id], ts.is_listened),\n",
    " batch_size = int(len(tr)/100), epochs = 5) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_index</th>\n",
       "      <th>is_listened</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>241</th>\n",
       "      <td>241</td>\n",
       "      <td>0.921215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1559</th>\n",
       "      <td>1559</td>\n",
       "      <td>0.681611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>1657</td>\n",
       "      <td>0.819947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1665</th>\n",
       "      <td>1665</td>\n",
       "      <td>0.761090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1666</th>\n",
       "      <td>1666</td>\n",
       "      <td>0.761090</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      row_index  is_listened\n",
       "241         241     0.921215\n",
       "1559       1559     0.681611\n",
       "1657       1657     0.819947\n",
       "1665       1665     0.761090\n",
       "1666       1666     0.761090"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict validation data\n",
    "pred = pd.DataFrame()\n",
    "pred[\"row_index\"] = ts.row_index\n",
    "pred[\"is_listened\"] = model.predict([ts.user_id, ts.context_type])\n",
    "pred.to_csv(path + \"pred_valid/keras_newdata_full_simpleDotRecommender50_adagrad_25ep.csv\", index = False)\n",
    "pred.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.65473497808416758"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# computing AUC\n",
    "metrics.roc_auc_score(ts.is_listened, pred.is_listened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "user_in (InputLayer)             (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "song_in (InputLayer)             (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)          (None, 1, 50)         975250      user_in[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)          (None, 1, 50)         12351900    song_in[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dot_1 (Dot)                      (None, 1, 1)          0           embedding_1[0][0]                \n",
      "                                                                   embedding_2[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)          (None, 1, 1)          19505       user_in[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 1)             0           dot_1[0][0]                      \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 1)             0           embedding_5[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)          (None, 1, 1)          247038      song_in[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "add_1 (Add)                      (None, 1)             0           flatten_3[0][0]                  \n",
      "                                                                   flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 1)             0           embedding_6[0][0]                \n",
      "____________________________________________________________________________________________________\n",
      "add_2 (Add)                      (None, 1)             0           add_1[0][0]                      \n",
      "                                                                   flatten_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1)             2           add_2[0][0]                      \n",
      "====================================================================================================\n",
      "Total params: 13,593,695\n",
      "Trainable params: 13,593,695\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_bias = pd.DataFrame(data = model.layers[5].get_weights()[0], columns = [\"user_bias\"])\n",
    "song_bias = pd.DataFrame(data = model.layers[8].get_weights()[0], columns = [\"song_bias\"])\n",
    "user_embeddings = pd.DataFrame(data = model.layers[2].get_weights()[0])\n",
    "song_embeddings = pd.DataFrame(data = model.layers[3].get_weights()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user_bias.to_csv(path + \"data/user_bias_recommender0519.csv\", index = True)\n",
    "song_bias.to_csv(path + \"data/song_bias_recommender0519.csv\", index = True)\n",
    "user_embeddings.to_csv(path + \"data/user_embeddings_recommender0519.csv\", index = True)\n",
    "song_embeddings.to_csv(path + \"data/song_embeddings_recommender0519.csv\", index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. SECOND STAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "7558834/7558834 [==============================] - 46s - loss: 0.4977 - acc: 0.7601    \n",
      "Epoch 2/5\n",
      "7558834/7558834 [==============================] - 45s - loss: 0.4969 - acc: 0.7603    \n",
      "Epoch 3/5\n",
      "7558834/7558834 [==============================] - 42s - loss: 0.4962 - acc: 0.7606    \n",
      "Epoch 4/5\n",
      "7558834/7558834 [==============================] - 43s - loss: 0.4955 - acc: 0.7608    \n",
      "Epoch 5/5\n",
      "7558834/7558834 [==============================] - 40s - loss: 0.4949 - acc: 0.7610    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1cd372ef0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the estimations on full known data\n",
    "model.fit([kn.user_id, kn.media_id], kn.is_listened,\n",
    "batch_size = int(kn.shape[0]/100), epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>is_listened</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7022297</th>\n",
       "      <td>0</td>\n",
       "      <td>0.861538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3513324</th>\n",
       "      <td>1</td>\n",
       "      <td>0.827026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3513295</th>\n",
       "      <td>2</td>\n",
       "      <td>0.876625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4452282</th>\n",
       "      <td>3</td>\n",
       "      <td>0.742794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6338648</th>\n",
       "      <td>4</td>\n",
       "      <td>0.888280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sample_id  is_listened\n",
       "7022297          0     0.861538\n",
       "3513324          1     0.827026\n",
       "3513295          2     0.876625\n",
       "4452282          3     0.742794\n",
       "6338648          4     0.888280"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict unknown data\n",
    "pred = pd.DataFrame()\n",
    "pred[\"sample_id\"] = un.sample_id.astype(int)\n",
    "pred[\"is_listened\"] = model.predict([un.user_id, un.context_type])\n",
    "pred = pred.sort_values(\"sample_id\")\n",
    "pred.to_csv(path + \"pred_unknown/keras_newdata_full_simpleDotRecommender50_adagrad_25ep.csv\", index = False)\n",
    "pred.head(5)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
