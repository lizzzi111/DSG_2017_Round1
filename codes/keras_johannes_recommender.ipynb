{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "#!pip install rpy2\n",
    "#!pip install pandas\n",
    "#!pip install keras\n",
    "#!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "# libraries\n",
    "#import rpy2.robjects as robjects\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras.layers import Input, Dense, Embedding, concatenate, Flatten, Dropout, Reshape, dot, add\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7578752, 57)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the data\n",
    "path = \"/Users/hauptjoh/Dropbox/DSG17/DSG_2017/\"\n",
    "data = pd.read_csv(path + \"data/data_full.csv\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add observation index\n",
    "data[\"row_index\"] = data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (7389336, 58)\n",
      "test: (169498, 58)\n",
      "known: (7558834, 58)\n",
      "unknown: (19918, 58)\n"
     ]
    }
   ],
   "source": [
    "# data partitioning\n",
    "tr = data.query(\"dataset == 'train'\")\n",
    "ts = data.query(\"dataset == 'test'\")\n",
    "kn = data.query(\"dataset != 'unknown'\")\n",
    "un = data.query(\"dataset == 'unknown'\")\n",
    "\n",
    "# print data sizes\n",
    "print(\"train: \"   + str(tr.shape))\n",
    "print(\"test: \"    + str(ts.shape))\n",
    "print(\"known: \"   + str(kn.shape))\n",
    "print(\"unknown: \" + str(un.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['user_id', 'media_id', 'artist_id', 'genre_id', 'album_id',\n",
      "       'context_type', 'media_duration', 'listen_type', 'user_gender',\n",
      "       'user_age', 'is_listened', 'sample_id', 'dataset', 'time_lag',\n",
      "       'session_id', 'song_session_position', 'first_flow',\n",
      "       'time_diff_release_listen', 'release_year', 'is_listened_lag1',\n",
      "       'is_listened_lag2', 'user_skip_ratio_last5', 'genre_equal_last_song',\n",
      "       'artist_equal_last_song', 'album_equal_last_song', 'genre_plays',\n",
      "       'genre_skips', 'artist_plays', 'artist_skips', 'album_plays',\n",
      "       'album_skips', 'song_plays', 'song_skips', 'user_ratio_flow',\n",
      "       'user_ratio_othr', 'genre_ratio', 'artist_ratio', 'song_ratio',\n",
      "       'user_genre_ratio', 'user_artist_ratio', 'user_song_ratio',\n",
      "       'platform_name', 'platform_family', 'hour_of_day1', 'hour_of_day2',\n",
      "       'hour_of_day3', 'hour_of_day4', 'hour_of_day5', 'hour_of_day6',\n",
      "       'hour_of_day7', 'hour_of_day8', 'weekdayMon', 'weekdaySat',\n",
      "       'weekdaySun', 'weekdayThu', 'weekdayTue', 'weekdayWed', 'row_index'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# List numeric features used as predictors\n",
    "print(data.columns)\n",
    "numVars = [\"user_ratio_flow\", \"user_ratio_full\", \"listen_type\", \"first_flow\",\n",
    "           \"song_plays\", \"artist_plays\", \"platform_name1\", \"platform_name2\",\n",
    "           \"song_skips\", \"artist_skips\", \"song_session_position\", \"time_diff\"] \n",
    "\n",
    "# Create the data input matrix that can be passed to the keras model\n",
    "tr_data = tr[[column for column in tr.columns if column in numVars]].as_matrix()\n",
    "ts_data = ts[[column for column in ts.columns if column in numVars]].as_matrix()\n",
    "kn_data = kn[[column for column in kn.columns if column in numVars]].as_matrix()\n",
    "un_data = un[[column for column in un.columns if column in numVars]].as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. MODELING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. INITIALIZING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an input layer with embeddings\n",
    "user_in    = Input(shape = (1,), dtype = 'int64',   name = \"user_in\")\n",
    "song_in    = Input(shape = (1,), dtype = 'int64',   name = \"song_in\")\n",
    "artist_in  = Input(shape = (1,), dtype = 'int64',   name = \"artist_in\")\n",
    "context_in = Input(shape = (1,), dtype = 'int64',   name = \"context_in\")\n",
    "\n",
    "# Create an input layer with numeric features\n",
    "data_in = Input(shape = (tr_data.shape[1],), name = \"data_in\")\n",
    "\n",
    "# Counting number of unique ID values\n",
    "n_users   = tr.user_id.nunique()\n",
    "n_songs   = tr.media_id.nunique()\n",
    "n_artists = tr.artist_id.nunique()\n",
    "n_context = tr.context_type.nunique()\n",
    "\n",
    "# Create an embedding assigning k latent factors to each ID\n",
    "u = Embedding(n_users,   50, input_length = 1, embeddings_regularizer = l2(1e-5))(user_in)\n",
    "s = Embedding(n_songs,   50, input_length = 1, embeddings_regularizer = l2(1e-5))(song_in)\n",
    "a = Embedding(n_artists, 50, input_length = 1, embeddings_regularizer = l2(1e-5))(artist_in)\n",
    "c = Embedding(n_context, 50, input_length = 1, embeddings_regularizer = l2(1e-5))(context_in)\n",
    "\n",
    "# Also create 'biases', i.e. a user and song specific value that is added\n",
    "ub = Flatten()(Embedding(n_users, 1, input_length = 1)(user_in))\n",
    "sb = Flatten()(Embedding(n_songs, 1, input_length = 1)(song_in))\n",
    "\n",
    "# Layer with embeddings\n",
    "x = dot([u, s], axes = 2)\n",
    "x = Flatten()(x)\n",
    "x = add([x, ub])\n",
    "x = add([x, sb])\n",
    "output = Dense(1, activation = \"sigmoid\")(x)\n",
    "\n",
    "# Specify the model that we want to use\n",
    "model = Model([user_in, song_in], output)\n",
    "model.compile(optimizer = \"Adagrad\", loss = \"binary_crossentropy\", metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. FIRST STAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7389336 samples, validate on 169498 samples\n",
      "Epoch 1/30\n",
      "7389336/7389336 [==============================] - 22s - loss: 0.6202 - acc: 0.7212 - val_loss: 0.6394 - val_acc: 0.6759\n",
      "Epoch 2/30\n",
      "7389336/7389336 [==============================] - 22s - loss: 0.5812 - acc: 0.7394 - val_loss: 0.6298 - val_acc: 0.6785\n",
      "Epoch 3/30\n",
      "7389336/7389336 [==============================] - 21s - loss: 0.5680 - acc: 0.7416 - val_loss: 0.6230 - val_acc: 0.6796\n",
      "Epoch 4/30\n",
      "7389336/7389336 [==============================] - 22s - loss: 0.5588 - acc: 0.7428 - val_loss: 0.6180 - val_acc: 0.6805\n",
      "Epoch 5/30\n",
      "7389336/7389336 [==============================] - 24s - loss: 0.5519 - acc: 0.7438 - val_loss: 0.6141 - val_acc: 0.6810\n",
      "Epoch 6/30\n",
      "7389336/7389336 [==============================] - 24s - loss: 0.5463 - acc: 0.7448 - val_loss: 0.6111 - val_acc: 0.6816\n",
      "Epoch 7/30\n",
      "7389336/7389336 [==============================] - 23s - loss: 0.5416 - acc: 0.7456 - val_loss: 0.6087 - val_acc: 0.6820\n",
      "Epoch 8/30\n",
      "7389336/7389336 [==============================] - 23s - loss: 0.5377 - acc: 0.7464 - val_loss: 0.6070 - val_acc: 0.6820\n",
      "Epoch 9/30\n",
      "7389336/7389336 [==============================] - 23s - loss: 0.5342 - acc: 0.7471 - val_loss: 0.6055 - val_acc: 0.6821\n",
      "Epoch 10/30\n",
      "7389336/7389336 [==============================] - 23s - loss: 0.5312 - acc: 0.7479 - val_loss: 0.6043 - val_acc: 0.6825\n",
      "Epoch 11/30\n",
      "7389336/7389336 [==============================] - 24s - loss: 0.5286 - acc: 0.7485 - val_loss: 0.6034 - val_acc: 0.6825\n",
      "Epoch 12/30\n",
      "7389336/7389336 [==============================] - 23s - loss: 0.5262 - acc: 0.7490 - val_loss: 0.6025 - val_acc: 0.6826\n",
      "Epoch 13/30\n",
      "7389336/7389336 [==============================] - 22s - loss: 0.5241 - acc: 0.7496 - val_loss: 0.6022 - val_acc: 0.6826\n",
      "Epoch 14/30\n",
      "7389336/7389336 [==============================] - 21s - loss: 0.5222 - acc: 0.7501 - val_loss: 0.6012 - val_acc: 0.6826\n",
      "Epoch 15/30\n",
      "7389336/7389336 [==============================] - 21s - loss: 0.5205 - acc: 0.7505 - val_loss: 0.6011 - val_acc: 0.6824\n",
      "Epoch 16/30\n",
      "7389336/7389336 [==============================] - 21s - loss: 0.5189 - acc: 0.7509 - val_loss: 0.6009 - val_acc: 0.6824\n",
      "Epoch 17/30\n",
      "7389336/7389336 [==============================] - 21s - loss: 0.5174 - acc: 0.7513 - val_loss: 0.6008 - val_acc: 0.6824\n",
      "Epoch 18/30\n",
      "7389336/7389336 [==============================] - 21s - loss: 0.5161 - acc: 0.7516 - val_loss: 0.6005 - val_acc: 0.6824\n",
      "Epoch 19/30\n",
      "7389336/7389336 [==============================] - 21s - loss: 0.5149 - acc: 0.7519 - val_loss: 0.6004 - val_acc: 0.6823\n",
      "Epoch 20/30\n",
      "7389336/7389336 [==============================] - 21s - loss: 0.5138 - acc: 0.7523 - val_loss: 0.6005 - val_acc: 0.6823\n",
      "Epoch 21/30\n",
      "7389336/7389336 [==============================] - 22s - loss: 0.5128 - acc: 0.7525 - val_loss: 0.6003 - val_acc: 0.6825\n",
      "Epoch 22/30\n",
      "7389336/7389336 [==============================] - 23s - loss: 0.5119 - acc: 0.7528 - val_loss: 0.6003 - val_acc: 0.6826\n",
      "Epoch 23/30\n",
      "7389336/7389336 [==============================] - 25s - loss: 0.5110 - acc: 0.7531 - val_loss: 0.6007 - val_acc: 0.6826\n",
      "Epoch 24/30\n",
      "7389336/7389336 [==============================] - 23s - loss: 0.5102 - acc: 0.7533 - val_loss: 0.6005 - val_acc: 0.6827\n",
      "Epoch 25/30\n",
      "7389336/7389336 [==============================] - 23s - loss: 0.5094 - acc: 0.7535 - val_loss: 0.6009 - val_acc: 0.6827\n",
      "Epoch 26/30\n",
      "7389336/7389336 [==============================] - 22s - loss: 0.5087 - acc: 0.7537 - val_loss: 0.6010 - val_acc: 0.6826\n",
      "Epoch 27/30\n",
      "7389336/7389336 [==============================] - 23s - loss: 0.5081 - acc: 0.7539 - val_loss: 0.6012 - val_acc: 0.6826\n",
      "Epoch 28/30\n",
      "7389336/7389336 [==============================] - 23s - loss: 0.5075 - acc: 0.7540 - val_loss: 0.6014 - val_acc: 0.6824\n",
      "Epoch 29/30\n",
      "7389336/7389336 [==============================] - 23s - loss: 0.5069 - acc: 0.7541 - val_loss: 0.6015 - val_acc: 0.6824\n",
      "Epoch 30/30\n",
      "7389336/7389336 [==============================] - 22s - loss: 0.5064 - acc: 0.7543 - val_loss: 0.6017 - val_acc: 0.6822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x10fc2eb00>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the estimations on training data\n",
    "model.fit([tr.user_id, tr.media_id], tr.is_listened, \n",
    "validation_data = ([ts.user_id, ts.media_id], ts.is_listened),\n",
    " batch_size = int(len(tr)/100), epochs = 30) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_index</th>\n",
       "      <th>is_listened</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>102</td>\n",
       "      <td>0.929960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>108</td>\n",
       "      <td>0.923464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>207</td>\n",
       "      <td>0.966134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>415</td>\n",
       "      <td>0.923464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>513</td>\n",
       "      <td>0.923464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     row_index  is_listened\n",
       "102        102     0.929960\n",
       "108        108     0.923464\n",
       "207        207     0.966134\n",
       "415        415     0.923464\n",
       "513        513     0.923464"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict validation data\n",
    "pred = pd.DataFrame()\n",
    "pred[\"row_index\"] = ts.row_index\n",
    "pred[\"is_listened\"] = model.predict([ts.user_id, ts.context_type])\n",
    "pred.to_csv(path + \"pred_valid/keras_newdata_full_simpleDotRecommender50_adagrad_30ep.csv\", index = False)\n",
    "pred.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66190419896941077"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# computing AUC\n",
    "metrics.roc_auc_score(ts.is_listened, pred.is_listened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "user_in (InputLayer)             (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "song_in (InputLayer)             (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)          (None, 1, 50)         681500                                       \n",
      "____________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)          (None, 1, 50)         3770900                                      \n",
      "____________________________________________________________________________________________________\n",
      "dot_1 (Dot)                      (None, 1, 1)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)          (None, 1, 1)          13630                                        \n",
      "____________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)              (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)          (None, 1, 1)          75418                                        \n",
      "____________________________________________________________________________________________________\n",
      "add_1 (Add)                      (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)              (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "add_2 (Add)                      (None, 1)             0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 1)             2                                            \n",
      "====================================================================================================\n",
      "Total params: 4,541,450\n",
      "Trainable params: 4,541,450\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_bias = pd.DataFrame(data = model.layers[5].get_weights()[0], columns = [\"user_bias\"])\n",
    "song_bias = pd.DataFrame(data = model.layers[8].get_weights()[0], columns = [\"song_bias\"])\n",
    "user_embeddings = pd.DataFrame(data = model.layers[2].get_weights()[0])\n",
    "song_embeddings = pd.DataFrame(data = model.layers[3].get_weights()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_bias.to_csv(path + \"data/user_bias_recommender0519.csv\", index = True)\n",
    "song_bias.to_csv(path + \"data/song_bias_recommender0519.csv\", index = True)\n",
    "user_embeddings.to_csv(path + \"data/user_embeddings_recommender0519.csv\", index = True)\n",
    "song_embeddings.to_csv(path + \"data/song_embeddings_recommender0519.csv\", index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. SECOND STAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "7558834/7558834 [==============================] - 32s - loss: 0.5080 - acc: 0.7528    \n",
      "Epoch 2/10\n",
      "7558834/7558834 [==============================] - 23s - loss: 0.5076 - acc: 0.7529    \n",
      "Epoch 3/10\n",
      "7558834/7558834 [==============================] - 24s - loss: 0.5071 - acc: 0.7530    \n",
      "Epoch 4/10\n",
      "7558834/7558834 [==============================] - 23s - loss: 0.5067 - acc: 0.7531    \n",
      "Epoch 5/10\n",
      "7558834/7558834 [==============================] - 23s - loss: 0.5064 - acc: 0.7532    \n",
      "Epoch 6/10\n",
      "7558834/7558834 [==============================] - 22s - loss: 0.5060 - acc: 0.7533    \n",
      "Epoch 7/10\n",
      "7558834/7558834 [==============================] - 23s - loss: 0.5057 - acc: 0.7534    \n",
      "Epoch 8/10\n",
      "7558834/7558834 [==============================] - 23s - loss: 0.5054 - acc: 0.7535    \n",
      "Epoch 9/10\n",
      "7558834/7558834 [==============================] - 22s - loss: 0.5051 - acc: 0.7536    \n",
      "Epoch 10/10\n",
      "7558834/7558834 [==============================] - 21s - loss: 0.5048 - acc: 0.7537    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b0e3f710>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the estimations on full known data\n",
    "model.fit([kn.user_id, kn.media_id], kn.is_listened,\n",
    "batch_size = int(kn.shape[0]/100), epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>is_listened</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7551764</th>\n",
       "      <td>0</td>\n",
       "      <td>0.889594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6913498</th>\n",
       "      <td>1</td>\n",
       "      <td>0.838145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6529338</th>\n",
       "      <td>2</td>\n",
       "      <td>0.876226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5409308</th>\n",
       "      <td>3</td>\n",
       "      <td>0.730301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6218645</th>\n",
       "      <td>4</td>\n",
       "      <td>0.905385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sample_id  is_listened\n",
       "7551764          0     0.889594\n",
       "6913498          1     0.838145\n",
       "6529338          2     0.876226\n",
       "5409308          3     0.730301\n",
       "6218645          4     0.905385"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict unknown data\n",
    "pred = pd.DataFrame()\n",
    "pred[\"sample_id\"] = un.sample_id.astype(int)\n",
    "pred[\"is_listened\"] = model.predict([un.user_id, un.context_type])\n",
    "pred = pred.sort_values(\"sample_id\")\n",
    "pred.to_csv(path + \"pred_unknown/keras_newdata_full_simpleDotRecommender50_adagrad_30ep.csv\", index = False)\n",
    "pred.head(5)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
