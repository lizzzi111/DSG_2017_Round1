{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# libraries\n",
    "#!pip install rpy2\n",
    "#!pip install pandas\n",
    "#!pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the necessary packages, especially the keras layers using hte layer names directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# libraries\n",
    "#import rpy2.robjects as robjects\n",
    "import pandas as pd\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.layers import Input, Dense, Embedding, concatenate, Flatten, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the data\n",
    "#path = \"/Users/Kozodoi/Documents/Competitions/DSG_2017/\"\n",
    "path = \"/Users/maj/Dropbox/DSG17/DSG_2017/\"\n",
    "data   = pd.read_csv(path + \"data/data_full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['user_id', 'media_id', 'artist_id', 'genre_id', 'album_id',\n",
      "       'context_type', 'media_duration', 'listen_type', 'user_gender',\n",
      "       'user_age', 'is_listened', 'sample_id', 'dataset', 'time_lag',\n",
      "       'session_id', 'song_session_position', 'first_flow', 'time_diff',\n",
      "       'hours', 'genre_plays', 'genre_skips', 'artist_plays', 'artist_skips',\n",
      "       'album_plays', 'album_skips', 'song_plays', 'song_skips',\n",
      "       'user_ratio_flow', 'user_ratio_full', 'genre_ratio', 'artist_ratio',\n",
      "       'song_ratio', 'platform_name1', 'platform_name2', 'platform_family1',\n",
      "       'platform_family2'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the combined data into the training, test and unknown set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tr = data[data.dataset == 'train']\n",
    "ts = data[data.dataset == 'test']\n",
    "unknown = data[data.dataset == 'unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7365595, 36)\n",
      "(193239, 36)\n",
      "Index(['user_id', 'media_id', 'artist_id', 'genre_id', 'album_id',\n",
      "       'context_type', 'media_duration', 'listen_type', 'user_gender',\n",
      "       'user_age', 'is_listened', 'sample_id', 'dataset', 'time_lag',\n",
      "       'session_id', 'song_session_position', 'first_flow', 'time_diff',\n",
      "       'hours', 'genre_plays', 'genre_skips', 'artist_plays', 'artist_skips',\n",
      "       'album_plays', 'album_skips', 'song_plays', 'song_skips',\n",
      "       'user_ratio_flow', 'user_ratio_full', 'genre_ratio', 'artist_ratio',\n",
      "       'song_ratio', 'platform_name1', 'platform_name2', 'platform_family1',\n",
      "       'platform_family2'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# keep only Flow songs in the data\n",
    "# this proves to predict better, but some information is lost\n",
    "# !!! This currently messes up the ID assignment and needs to be corrected there.\n",
    "#tr = tr.query(\"listen_type == 1\")\n",
    "print(tr.shape)\n",
    "print(ts.shape)\n",
    "print(tr.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "tsu = ts.user_id.unique()\n",
    "tru = tr.user_id.unique()\n",
    "print([x for x in tsu if x not in tru])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the full feature set, create a subset of the data with the features that can be passed to the model directly. That is everything excluding the IDs and large factor variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the data input matrix that can be passed to the keras model\n",
    "# i.e. only numeric and without IDs and target variable\n",
    "dropVars = ['dataset','user_id', 'artist_id', 'media_id', \"genre_id\", \"album_id\", \"session_id\", \"is_listened\", \"sample_id\"]\n",
    "tr_data = tr[[column for column in tr.columns if column not in dropVars]].as_matrix()\n",
    "ts_data = ts[[column for column in tr.columns if column not in dropVars]].as_matrix()\n",
    "unknown_data = unknown[[column for column in tr.columns if column not in dropVars]].as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure of the keras model is as follows:\n",
    "- Input layers ot specify the size of the data that goes in the model\n",
    "- (Embedding layer, i.e. lookup table layer that assigns 50 values to each level. These values are then trained to somehow capture the essence of this level.)\n",
    "- Dense layer, i.e. fully connected neural net layers\n",
    "- Output layer, i.e. Dense layer with only one result and sigmoid activation (for a result between 0 and 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create an input layer with one row of IDs\n",
    "user_in   = Input(shape = (1,), dtype='int64', name = \"user_in\")\n",
    "#song_in   = Input(shape = (1,), dtype='int64', name = \"song_in\")\n",
    "artist_in = Input(shape = (1,), dtype='int64', name = \"artist_in\")\n",
    "genre_in  = Input(shape = (1,), dtype='int64', name = \"genre_in\")\n",
    "context_in = Input(shape = (1,), dtype='int64',   name = \"context_in\")\n",
    "\n",
    "# Create an embedding assigning k latent factors to each ID\n",
    "# These will be optimized\n",
    "# A regulariztaion is added to avoid very large weights\n",
    "n_users   = tr.user_id.nunique()\n",
    "#n_songs   = tr.media_id.nunique()\n",
    "n_artists = tr.artist_id.nunique()\n",
    "n_genres  = tr.genre_id.nunique()\n",
    "n_context = tr.context_type.nunique()\n",
    "\n",
    "# The layer needs the number of the input levels and the number of values for each level\n",
    "user_embedding = Embedding(n_users,   50, input_length=1, embeddings_regularizer=l2(1e-5))(user_in)\n",
    "#song_embedding = Embedding(n_songs,   50, input_length=1, embeddings_regularizer=l2(1e-5))(song_in)\n",
    "artist_embedding = Embedding(n_artists, 20, input_length=1, embeddings_regularizer=l2(1e-5))(artist_in)\n",
    "genre_embedding = Embedding(n_genres,  20, input_length=1, embeddings_regularizer=l2(1e-5))(genre_in)\n",
    "context_embedding = Embedding(n_context, 50, input_length=1, embeddings_regularizer=l2(1e-5))(context_in)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data input doesn't need any embedding and can directly be passed to a Dense layer\n",
    "data_in = Input(shape = (tr_data.shape[1],), name = \"data_in\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Specify what to do with the layers\n",
    "# We want to multiply them into a 'rating' matrix\n",
    "#song_embedding,\n",
    "embedding_input = concatenate([user_embedding,  artist_embedding, genre_embedding])\n",
    "embedding_input = Flatten()(embedding_input)\n",
    "embedding_dense = Dense(128, activation = \"relu\")(embedding_input)\n",
    "#embedding_dense = Flatten()(embedding_dense)\n",
    "\n",
    "#data_input = Flatten()(data_in)\n",
    "data_dense = Dense(128, activation = \"relu\")(data_in)\n",
    "data_dense = BatchNormalization()(data_dense)\n",
    "# Make into a vector, i.e. drop 2D structure\n",
    "# The 2D structure is important for e.g. CNN filters,\n",
    "# but not necessary in a dense layer, I think\n",
    "x = concatenate([embedding_dense, data_dense])\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "# Correct the standard devitation calculated from a batch\n",
    "# to better fit the 'true' sd\n",
    "x = BatchNormalization()(x)\n",
    "# \"Drop\" each node at a training stage with a certain probability \n",
    "# then reinsert it after the training run\n",
    "# Avoids overfitting and increases speed\n",
    "x = Dropout(0.5)(x)\n",
    "#x = Dropout(0.5)(Dense(128, activation='relu')(x))\n",
    "#x = BatchNormalization()(x)\n",
    "#x = Dense(64, activation='relu')(x) \n",
    "#x = Dropout(0.5)(x)\n",
    "output = Dense(1, activation = \"sigmoid\")(x)\n",
    "#x = merge([x, ub], mode = 'sum')\n",
    "#x = merge([x, sb], mode = 'sum') # Can this be included in the line above?\n",
    "\n",
    "# Then we specify the model that we want to use\n",
    "#song_in,\n",
    "model = Model([user_in,  artist_in, genre_in, data_in], output) # \n",
    "model.compile(Adam(0.001), loss=\"binary_crossentropy\", metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7365595 samples, validate on 193239 samples\n",
      "Epoch 1/1\n",
      "  45628/7365595 [..............................] - ETA: 558s - loss: 0.9659 - acc: 0.5096"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 19588 is out of bounds for size 19588\nApply node that caused the error: AdvancedSubtensor1(flatten_4/embedding_9/embeddings, Elemwise{Cast{int32}}.0)\nToposort index: 76\nInputs types: [TensorType(float32, matrix), TensorType(int32, vector)]\nInputs shapes: [(19588, 20), (22814,)]\nInputs strides: [(80, 4), (4,)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [[Reshape{3}(AdvancedSubtensor1.0, MakeVector{dtype='int64'}.0)]]\n\nBacktrace when the node is created(use Theano flag traceback.limit=N to make it longer):\n  File \"/Users/maj/anaconda/envs/deeplearning/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/maj/anaconda/envs/deeplearning/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2683, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/maj/anaconda/envs/deeplearning/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2787, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/maj/anaconda/envs/deeplearning/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2847, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-46-6983e20fc25f>\", line 20, in <module>\n    artist_embedding = Embedding(n_artists, 20, input_length=1, embeddings_regularizer=l2(1e-5))(artist_in)\n  File \"/Users/maj/anaconda/envs/deeplearning/lib/python3.6/site-packages/keras/engine/topology.py\", line 578, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/Users/maj/anaconda/envs/deeplearning/lib/python3.6/site-packages/keras/layers/embeddings.py\", line 120, in call\n    out = K.gather(self.embeddings, inputs)\n  File \"/Users/maj/anaconda/envs/deeplearning/lib/python3.6/site-packages/keras/backend/theano_backend.py\", line 404, in gather\n    y = reference[indices]\n\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/Users/maj/anaconda/envs/deeplearning/lib/python3.6/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 19588 is out of bounds for size 19588",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-0cb63a168eb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m model.fit([tr.user_id,  tr.artist_id, tr.genre_id, tr_data], tr.is_listened,  #\n\u001b[1;32m      5\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0martist_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenre_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts_data\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_listened\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m batch_size = 22814, epochs = 1)\n\u001b[0m",
      "\u001b[0;32m/Users/maj/anaconda/envs/deeplearning/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/maj/anaconda/envs/deeplearning/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m   1139\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1142\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/maj/anaconda/envs/deeplearning/lib/python3.6/site-packages/keras/backend/theano_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1122\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/maj/anaconda/envs/deeplearning/lib/python3.6/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    896\u001b[0m                     \u001b[0mnode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                     \u001b[0mthunk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mthunk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m                     storage_map=getattr(self.fn, 'storage_map', None))\n\u001b[0m\u001b[1;32m    899\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m                 \u001b[0;31m# old-style linkers raise their own exceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/maj/anaconda/envs/deeplearning/lib/python3.6/site-packages/theano/gof/link.py\u001b[0m in \u001b[0;36mraise_with_op\u001b[0;34m(node, thunk, exc_info, storage_map)\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# extra long error message in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m     \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_trace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/maj/anaconda/envs/deeplearning/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/maj/anaconda/envs/deeplearning/lib/python3.6/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 19588 is out of bounds for size 19588\nApply node that caused the error: AdvancedSubtensor1(flatten_4/embedding_9/embeddings, Elemwise{Cast{int32}}.0)\nToposort index: 76\nInputs types: [TensorType(float32, matrix), TensorType(int32, vector)]\nInputs shapes: [(19588, 20), (22814,)]\nInputs strides: [(80, 4), (4,)]\nInputs values: ['not shown', 'not shown']\nOutputs clients: [[Reshape{3}(AdvancedSubtensor1.0, MakeVector{dtype='int64'}.0)]]\n\nBacktrace when the node is created(use Theano flag traceback.limit=N to make it longer):\n  File \"/Users/maj/anaconda/envs/deeplearning/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/maj/anaconda/envs/deeplearning/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2683, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/maj/anaconda/envs/deeplearning/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2787, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/maj/anaconda/envs/deeplearning/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2847, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-46-6983e20fc25f>\", line 20, in <module>\n    artist_embedding = Embedding(n_artists, 20, input_length=1, embeddings_regularizer=l2(1e-5))(artist_in)\n  File \"/Users/maj/anaconda/envs/deeplearning/lib/python3.6/site-packages/keras/engine/topology.py\", line 578, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"/Users/maj/anaconda/envs/deeplearning/lib/python3.6/site-packages/keras/layers/embeddings.py\", line 120, in call\n    out = K.gather(self.embeddings, inputs)\n  File \"/Users/maj/anaconda/envs/deeplearning/lib/python3.6/site-packages/keras/backend/theano_backend.py\", line 404, in gather\n    y = reference[indices]\n\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "# run the estimations\n",
    "#tr.media_id,\n",
    "#ts.media_id,\n",
    "model.fit([tr.user_id,  tr.artist_id, tr.genre_id, tr_data], tr.is_listened,  #\n",
    "validation_data = ([ts.user_id,  ts.artist_id, ts.genre_id, ts_data], ts.is_listened),\n",
    "batch_size = 22814, epochs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predict on unlabelled set\n",
    "pred = pd.DataFrame()\n",
    "pred[\"sample_id\"] = unknown.sample_id\n",
    "pred[\"is_listened\"] = model.predict([unknown.userIdx, unknown.songIdx, unknown.artistIdx, unknown.genreIdx])\n",
    "pred.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# adding naive submission\n",
    "naive = pd.read_csv(path + \"submissions/naive_ratio_user.csv\")\n",
    "pred_mean = pred\n",
    "pred_mean[\"is_listened\"] = (pred[\"is_listened\"] + naive[\"is_listened\"])/2\n",
    "pred_mean.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# saving submissions\n",
    "pred.to_csv(path + \"submissions/deep_128_64_flow.csv\", index = False)\n",
    "pred.to_csv(path + \"submissions/deep_128_64_flow_plus_ratio_user.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [deeplearning]",
   "language": "python",
   "name": "Python [deeplearning]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
