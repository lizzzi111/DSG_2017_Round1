{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# libraries\n",
    "#!pip install rpy2\n",
    "#!pip install pandas\n",
    "#!pip install keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the necessary packages, especially the keras layers using hte layer names directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# libraries\n",
    "#import rpy2.robjects as robjects\n",
    "import pandas as pd\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.layers import Input, Dense, Embedding, concatenate, Flatten, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the data\n",
    "#path = \"/Users/Kozodoi/Documents/Competitions/DSG_2017/\"\n",
    "path = \"/Users/maj/Dropbox/DSG17/DSG_2017/\"\n",
    "data   = pd.read_csv(path + \"data/data_full.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['user_id', 'media_id', 'artist_id', 'genre_id', 'album_id',\n",
      "       'context_type', 'media_duration', 'listen_type', 'user_gender',\n",
      "       'user_age', 'is_listened', 'sample_id', 'dataset', 'time_lag',\n",
      "       'session_id', 'song_session_position', 'first_flow', 'time_diff',\n",
      "       'hours', 'genre_plays', 'genre_skips', 'artist_plays', 'artist_skips',\n",
      "       'album_plays', 'album_skips', 'song_plays', 'song_skips',\n",
      "       'user_ratio_flow', 'user_ratio_full', 'genre_ratio', 'artist_ratio',\n",
      "       'song_ratio', 'platform_name1', 'platform_name2', 'platform_family1',\n",
      "       'platform_family2'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the combined data into the training, test and unknown set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot compare a dtyped [object] array with a scalar of type [bool]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/Users/maj/anaconda/envs/deeplearning/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    876\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    878\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/maj/anaconda/envs/deeplearning/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    126\u001b[0m                                    names('rand_'), op('&')),\n\u001b[0;32m--> 127\u001b[0;31m                  ror_=bool_method(lambda x, y: operator.or_(y, x),\n\u001b[0m\u001b[1;32m    128\u001b[0m                                   names('ror_'), op('|')),\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for |: 'str' and 'str'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/Users/maj/anaconda/envs/deeplearning/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    894\u001b[0m                         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar_binop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/lib.pyx\u001b[0m in \u001b[0;36mpandas.lib.scalar_binop (pandas/lib.c:16407)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Users/maj/anaconda/envs/deeplearning/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    126\u001b[0m                                    names('rand_'), op('&')),\n\u001b[0;32m--> 127\u001b[0;31m                  ror_=bool_method(lambda x, y: operator.or_(y, x),\n\u001b[0m\u001b[1;32m    128\u001b[0m                                   names('ror_'), op('|')),\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for |: 'bool' and 'str'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-7f9b419588ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mknown\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0munknown\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'unknown'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/maj/anaconda/envs/deeplearning/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    927\u001b[0m                       is_integer_dtype(np.asarray(other)) else fill_bool)\n\u001b[1;32m    928\u001b[0m             return filler(self._constructor(\n\u001b[0;32m--> 929\u001b[0;31m                 \u001b[0mna_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m                 index=self.index)).__finalize__(self)\n\u001b[1;32m    931\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/maj/anaconda/envs/deeplearning/lib/python3.6/site-packages/pandas/core/ops.py\u001b[0m in \u001b[0;36mna_op\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    897\u001b[0m                     raise TypeError(\"cannot compare a dtyped [{0}] array with \"\n\u001b[1;32m    898\u001b[0m                                     \"a scalar of type [{1}]\".format(\n\u001b[0;32m--> 899\u001b[0;31m                                         x.dtype, type(y).__name__))\n\u001b[0m\u001b[1;32m    900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot compare a dtyped [object] array with a scalar of type [bool]"
     ]
    }
   ],
   "source": [
    "tr = data[data.dataset == 'train']\n",
    "ts = data[data.dataset == 'test']\n",
    "known = data[data.dataset == 'train' | data.dataset == 'test']\n",
    "unknown = data[data.dataset == 'unknown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2275140, 36)\n",
      "(193239, 36)\n",
      "Index(['user_id', 'media_id', 'artist_id', 'genre_id', 'album_id',\n",
      "       'context_type', 'media_duration', 'listen_type', 'user_gender',\n",
      "       'user_age', 'is_listened', 'sample_id', 'dataset', 'time_lag',\n",
      "       'session_id', 'song_session_position', 'first_flow', 'time_diff',\n",
      "       'hours', 'genre_plays', 'genre_skips', 'artist_plays', 'artist_skips',\n",
      "       'album_plays', 'album_skips', 'song_plays', 'song_skips',\n",
      "       'user_ratio_flow', 'user_ratio_full', 'genre_ratio', 'artist_ratio',\n",
      "       'song_ratio', 'platform_name1', 'platform_name2', 'platform_family1',\n",
      "       'platform_family2'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# keep only Flow songs in the data\n",
    "# this proves to predict better, but some information is lost\n",
    "tr = tr.query(\"listen_type == 1\")\n",
    "print(tr.shape)\n",
    "print(ts.shape)\n",
    "print(tr.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13451\n",
      "13451\n",
      "16826\n",
      "16826\n",
      "1334\n",
      "1334\n",
      "55975\n",
      "55975\n",
      "34\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "print(data.user_id.nunique())\n",
    "print(tr.user_id.nunique())\n",
    "print(data.artist_id.nunique())\n",
    "print(tr.artist_id.nunique())\n",
    "print(data.genre_id.nunique())\n",
    "print(tr.genre_id.nunique())\n",
    "print(data.media_id.nunique())\n",
    "print(tr.media_id.nunique())\n",
    "print(data.context_type.nunique())\n",
    "print(tr.context_type.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum value should be equal to the number of unique values - 1 (Python indexing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55974"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(tr.media_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the full feature set, create a subset of the data with the features that can be passed to the model directly. That is everything excluding the IDs and large factor variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the data input matrix that can be passed to the keras model\n",
    "# i.e. only numeric and without IDs and target variable\n",
    "dropVars = ['dataset','user_id', 'artist_id', 'media_id', \"genre_id\", \"album_id\", \"session_id\", \"is_listened\", \"sample_id\"]\n",
    "tr_data = tr[[column for column in tr.columns if column not in dropVars]].as_matrix()\n",
    "ts_data = ts[[column for column in ts.columns if column not in dropVars]].as_matrix()\n",
    "known_data = known[[column for column in known.columns if column not in dropVars]].as_matrix()\n",
    "unknown_data = unknown[[column for column in unknown.columns if column not in dropVars]].as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The structure of the keras model is as follows:\n",
    "- Input layers ot specify the size of the data that goes in the model\n",
    "- (Embedding layer, i.e. lookup table layer that assigns 50 values to each level. These values are then trained to somehow capture the essence of this level.)\n",
    "- Dense layer, i.e. fully connected neural net layers\n",
    "- Output layer, i.e. Dense layer with only one result and sigmoid activation (for a result between 0 and 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create an input layer with one row of IDs\n",
    "user_in   = Input(shape = (1,), dtype='int64', name = \"user_in\")\n",
    "song_in   = Input(shape = (1,), dtype='int64', name = \"song_in\")\n",
    "artist_in = Input(shape = (1,), dtype='int64', name = \"artist_in\")\n",
    "genre_in  = Input(shape = (1,), dtype='int64', name = \"genre_in\")\n",
    "context_in = Input(shape = (1,), dtype='int64',   name = \"context_in\")\n",
    "\n",
    "# Create an embedding assigning k latent factors to each ID\n",
    "# These will be optimized\n",
    "# A regulariztaion is added to avoid very large weights\n",
    "n_users   = tr.user_id.nunique()\n",
    "n_songs   = tr.media_id.nunique()\n",
    "n_artists = tr.artist_id.nunique()\n",
    "n_genres  = tr.genre_id.nunique()\n",
    "n_context = tr.context_type.nunique()\n",
    "\n",
    "# The layer needs the number of the input levels and the number of values for each level\n",
    "user_embedding = Embedding(n_users,   50, input_length=1, embeddings_regularizer=l2(1e-5))(user_in)\n",
    "song_embedding = Embedding(n_songs,   50, input_length=1, embeddings_regularizer=l2(1e-5))(song_in)\n",
    "artist_embedding = Embedding(n_artists, 20, input_length=1, embeddings_regularizer=l2(1e-5))(artist_in)\n",
    "genre_embedding = Embedding(n_genres,  20, input_length=1, embeddings_regularizer=l2(1e-5))(genre_in)\n",
    "context_embedding = Embedding(n_context, 50, input_length=1, embeddings_regularizer=l2(1e-5))(context_in)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data input doesn't need any embedding and can directly be passed to a Dense layer\n",
    "data_in = Input(shape = (tr_data.shape[1],), name = \"data_in\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Specify what to do with the layers\n",
    "# We want to multiply them into a 'rating' matrix\n",
    "#\n",
    "embedding_input = concatenate([user_embedding,  song_embedding, artist_embedding, genre_embedding])\n",
    "embedding_input = Flatten()(embedding_input)\n",
    "embedding_dense = Dense(128, activation = \"relu\")(embedding_input)\n",
    "embedding_dense = BatchNormalization()(embedding_dense)\n",
    "#embedding_dense = Flatten()(embedding_dense)\n",
    "\n",
    "#data_input = Flatten()(data_in)\n",
    "data_dense = Dense(128, activation = \"relu\")(data_in)\n",
    "data_dense = BatchNormalization()(data_dense)\n",
    "# Make into a vector, i.e. drop 2D structure\n",
    "# The 2D structure is important for e.g. CNN filters,\n",
    "# but not necessary in a dense layer, I think\n",
    "x = concatenate([embedding_dense, data_dense])\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "# Correct the standard devitation calculated from a batch\n",
    "# to better fit the 'true' sd\n",
    "x = BatchNormalization()(x)\n",
    "# \"Drop\" each node at a training stage with a certain probability \n",
    "# then reinsert it after the training run\n",
    "# Avoids overfitting and increases speed\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(64, activation='relu')(x) \n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(1, activation = \"sigmoid\")(x)\n",
    "#x = merge([x, ub], mode = 'sum')\n",
    "#x = merge([x, sb], mode = 'sum') # Can this be included in the line above?\n",
    "\n",
    "# Then we specify the model that we want to use\n",
    "#\n",
    "model = Model([user_in, song_in, artist_in, genre_in, data_in], output) # \n",
    "model.compile(Adam(0.001), loss=\"binary_crossentropy\", metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2275140 samples, validate on 193239 samples\n",
      "Epoch 1/3\n",
      "2275140/2275140 [==============================] - 202s - loss: 0.4829 - acc: 0.7714 - val_loss: 0.6236 - val_acc: 0.6888\n",
      "Epoch 2/3\n",
      "2275140/2275140 [==============================] - 198s - loss: 0.4767 - acc: 0.7736 - val_loss: 0.6208 - val_acc: 0.6844\n",
      "Epoch 3/3\n",
      "2275140/2275140 [==============================] - 200s - loss: 0.4718 - acc: 0.7760 - val_loss: 0.6308 - val_acc: 0.6629\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11f7d59b0>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run the estimations\n",
    "model.fit([tr.user_id, tr.media_id, tr.artist_id, tr.genre_id, tr_data], tr.is_listened,  #\n",
    "validation_data = ([ts.user_id, ts.media_id, ts.artist_id, ts.genre_id, ts_data], ts.is_listened),\n",
    "batch_size = 22814, epochs = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>media_id</th>\n",
       "      <th>is_listened</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.922893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.886547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.976968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.949659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.928772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  media_id  is_listened\n",
       "0        0         0     0.922893\n",
       "1        0         1     0.886547\n",
       "2        0         2     0.976968\n",
       "3        0         3     0.949659\n",
       "4        0         4     0.928772"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict validation data\n",
    "pred = pd.DataFrame()\n",
    "pred[\"user_id\"]  = ts.user_id\n",
    "pred[\"media_id\"] = ts.media_id\n",
    "pred[\"is_listened\"] = model.predict([ts.user_id, ts.media_id, ts.artist_id, ts.genre_id, ts_data])\n",
    "pred.to_csv(path + \"data/keras_ts_emd+data.csv\", index = False)\n",
    "pred.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'known' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-3a658d9e48c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# run the estimations on full known data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model.fit([known.user_id, known.media_id, known.artist_id, known.genre_id, known_data], known.is_listened,\n\u001b[0m\u001b[1;32m      3\u001b[0m batch_size = int(known.shape[0]/100), epochs = 5)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'known' is not defined"
     ]
    }
   ],
   "source": [
    "# run the estimations on full known data\n",
    "model.fit([known.user_id, known.media_id, known.artist_id, known.genre_id, known_data], known.is_listened,\n",
    "batch_size = int(known.shape[0]/100), epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict unknown data\n",
    "pred = pd.DataFrame()\n",
    "pred[\"sample_id\"] = unknown.sample_id\n",
    "pred[\"is_listened\"] = model.predict([unknown.userIdx, unknown.contextIdx])\n",
    "pred.to_csv(path + \"submissions/deep_keras_emb_data.csv\", index = False)\n",
    "pred.head(5)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [deeplearning]",
   "language": "python",
   "name": "Python [deeplearning]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
