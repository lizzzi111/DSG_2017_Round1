install.packages("foreach")
install.packages("doParallel")
library(doParallel)
library(foreach)
foreach(i = 1:10) %do% {
print(i)
}
foreach(i = 1:1000) %do% {
print(i)
}
detectCores()
cl <- makeCluster(detectCores() - 2)
cores <- detectCores() - 2
cl <- makeCluster(cores)
registerDoParallel(cl)
foreach(i = 1:10000) %do% {
print(i)
}
foreach(i = 1:10000) %dopar% {
print(i)
}
proc.time()
t <- proc.time()
foreach(i = 1:10000) %dopar% {
print(i)
}
proc.time() - t
t <- proc.time()
foreach(i = 1:10000) %do% {
print(i)
}
proc.time() - t
t <- proc.time()
foreach(i = 1:10000) %do% {
print(i)
}
x <- proc.time() - t
t <- proc.time()
foreach(i = 1:10000) %dopar% {
print(i)
}
x1 <- proc.time() - t
x
x1
cores <- detectCores() - 2
cl <- makeCluster(cores)
registerDoParallel(cl)
t <- proc.time()
foreach(i = 1:100000) %dopar% {
print(i)
}
xpar <- proc.time() - t
t <- proc.time()
foreach(i = 1:100000) %do% {
print(i)
}
x <- proc.time() - t
xpar
x
rm(list = ls())
library(doParallel)
library(foreach)
cores <- detectCores() - 2
cl <- makeCluster(cores)
registerDoParallel(cl)
t <- proc.time()
foreach(i = 1:100000) %dopar% {
print(i)
}
xpar <- proc.time() - t
t <- proc.time()
foreach(i = 1:100000) %do% {
print(i)
}
xdo <- proc.time() - t
t <- proc.time()
for (i in 1:100000) {
print(i)
}
x <- proc.time() - t
xpar
xdo
x
rm(list = ls())
load("~/Documents/Competitions/DSG_2017/back.Rdata")
xg.model
head(data.unknown)
###################################
#                                 #
#             SETTINGS            #
#                                 #
###################################
# clearing the memory
rm(list = ls())
# setting work directory
work.folder <- "/Users/Kozodoi/Documents/Competitions/DSG_2017"
setwd(work.folder)
# setting inner folders
code.folder <- "codes"
data.folder <- "data"
func.folder <- "functions"
subm.folder <- "submissions"
# loading libraries
if(require(pacman)==FALSE) install.packages("pacman")
library(pacman)
p_load(data.table, anytime, randomForest, AUC, caret, beepr, xgboost)
# loading functions
source(file.path(code.folder, "code_0_helper_functions.R"))
########## 1. LOADING THE DATA
# loading training data
data.train <- fread(file.path(data.folder, "train.csv"), sep = ",", dec = ".", header = T)
data.test  <- fread(file.path(data.folder, "test.csv"),  sep = ",", dec = ".", header = T)
# keeping only Flow songs
data.train <- data.train[data.train$listen_type == "1", ]
# merging data sets
data.test$is_listened <- NA
data.train$sample_id  <- NA
data.test$dataset  <- "test"
data.train$dataset <- "train"
data.full <- rbind(data.train, data.test)
setkey(data.full, user_id, media_id)
########## 2. CONVERTING VARIABLES
# converting factors
temp <- c("sample_id", "genre_id", "media_id", "album_id", "user_id", "artist_id", "user_gender", "context_type", "platform_name",
"platform_family", "listen_type", "is_listened")
data.full[, (temp) := lapply(.SD, factor), .SDcols = temp]
# converting timestamps
data.full[, release_date := as.Date(as.character(data.full$release_date), "%Y%m%d")]
data.full[, ts_listen := anytime(data.full$ts_listen, asUTC = T)]
# loading libraries
library(pacman)
pacman::p_load("anytime","data.table")
# Order data by user_id and ts_listen
# Using set* functions is faster
setorder(data.full, user_id, ts_listen)
#dt <- dt[order(ts_listen),.SD, by=user_id]
data.full[,time_lag:=c(NA, difftime(tail(ts_listen,-1), head(ts_listen,-1), units = "mins")), by = user_id]
data.full[is.na(time_lag), time_lag := 0]
#let's look at the most typical time lags
#summary(data.full$time_lag)
#let's take more than 30 mins as a start for a new session
#dt[,session_id := seq_along(time_lag), by = time_lag < 20]
data.full[, session_id := cumsum(time_lag>20)+1, by = user_id]
# Count the absolute position of the song in the session
data.full[, song_session_position := 1:.N, by = session_id]
# Find the index of the song in the flow
temp <- data.full[, list(listen_type = listen_type, session_id)]
temp[, flow_lag := shift(listen_type, fill = 0), by=session_id]
temp[, first_flow := as.numeric(listen_type == 1 & flow_lag == 0)]
#data.full[listen_type == "1", flow_position := cumsum(listen_type == "1" & shift(listen_type, fill = "0") == "0"), by = session_id]
data.full[, first_flow := temp$first_flow]
# Compute difference between the release date and listening date (number of days)
# NAs: release_date later than 2018; ts_listen before 2010 => substituted by mean values
# There are still 29,091 cases with time_diff < 0
data.full[, time_diff := as.numeric(as.Date(ts_listen) - release_date)]
data.full[ts_listen    < "2010-01-01", time_diff := NA]
data.full[release_date > "2018-01-01", time_diff := NA]
data.full[is.na(time_diff), time_diff := mean(data.full$time_diff, na.rm = T)]
#summary(data.full$time_diff)
# Create a factor variable for the hour of the day when the song is played
data.full[, hours := as.factor(format(as.POSIXct(data.full$ts_listen, format = "%H:%M:%S"),"%H"))]
# Create a lagged is_listened (for the previous song)
data.full[, is_listened_lag :=  shift(.SD), by = user_id, .SDcols = "is_listened"]
data.full[, is_listened_lag :=  as.numeric(is_listened_lag)-1]
data.full <- as.data.frame(data.full)
data.full[data.full$user_id == 0, ]
data.full[data.full$user_id == 0, c("user_id", "ts_listen", "is_listened", "is_listened_lag")]
tail(data.full[data.full$user_id == 0, c("user_id", "ts_listen", "is_listened", "is_listened_lag")])
tail(data.full[data.full$user_id == 1, c("user_id", "ts_listen", "is_listened", "is_listened_lag")])
tail(data.full[data.full$user_id == 2, c("user_id", "ts_listen", "is_listened", "is_listened_lag")])
tail(data.full[data.full$user_id == 3, c("user_id", "ts_listen", "is_listened", "is_listened_lag")])
tail(data.full[data.full$user_id == 4, c("user_id", "ts_listen", "is_listened", "is_listened_lag")])
tail(data.full[data.full$user_id == 5, c("user_id", "ts_listen", "is_listened", "is_listened_lag")])
tail(data.full[data.full$user_id == 6, c("user_id", "ts_listen", "is_listened", "is_listened_lag")])
tail(data.full[data.full$user_id == 7, c("user_id", "ts_listen", "is_listened", "is_listened_lag")])
tail(data.full[data.full$user_id == 8, c("user_id", "ts_listen", "is_listened", "is_listened_lag")])
tail(data.full[data.full$user_id == 9, c("user_id", "ts_listen", "is_listened", "is_listened_lag")])
tail(data.full[data.full$user_id == 10, c("user_id", "ts_listen", "is_listened", "is_listened_lag")])
tail(data.full[data.full$user_id == 12, c("user_id", "ts_listen", "is_listened", "is_listened_lag")])
tail(data.full[data.full$user_id == 20, c("user_id", "ts_listen", "is_listened", "is_listened_lag")])
tail(data.full[data.full$user_id == 100, c("user_id", "ts_listen", "is_listened", "is_listened_lag")])
tail(data.full[data.full$user_id == 1000, c("user_id", "ts_listen", "is_listened", "is_listened_lag")])
tail(data.full[data.full$user_id == 300, c("user_id", "ts_listen", "is_listened", "is_listened_lag")])
tail(data.full[data.full$user_id == 500, c("user_id", "ts_listen", "is_listened", "is_listened_lag")])
tail(data.full[data.full$user_id == 15555, c("user_id", "ts_listen", "is_listened", "is_listened_lag")])
tail(data.full[data.full$user_id == 11111, c("user_id", "ts_listen", "is_listened", "is_listened_lag")])
tail(data.full[data.full$user_id == 111, c("user_id", "ts_listen", "is_listened", "is_listened_lag")])
tail(data.full[data.full$user_id == 111, c("user_id", "ts_listen", "is_listened", "is_listened_lag", "session_id")])
tail(data.full[data.full$user_id == 3, c("user_id", "ts_listen", "is_listened", "is_listened_lag", "session_id")])
tail(data.full[data.full$user_id == 1, c("user_id", "ts_listen", "is_listened", "is_listened_lag", "session_id")])
tail(data.full[data.full$user_id == 2, c("user_id", "ts_listen", "is_listened", "is_listened_lag", "session_id")])
tail(data.full[data.full$user_id == 2, c("user_id", "ts_listen", "is_listened", "is_listened_lag", "song_session_position")])
# loading training data
data.train <- fread(file.path(data.folder, "train.csv"), sep = ",", dec = ".", header = T)
data.test  <- fread(file.path(data.folder, "test.csv"),  sep = ",", dec = ".", header = T)
# keeping only Flow songs
data.train <- data.train[data.train$listen_type == "1", ]
# merging data sets
data.test$is_listened <- NA
data.train$sample_id  <- NA
data.test$dataset  <- "test"
data.train$dataset <- "train"
data.full <- rbind(data.train, data.test)
setkey(data.full, user_id, media_id)
########## 2. CONVERTING VARIABLES
# converting factors
temp <- c("sample_id", "genre_id", "media_id", "album_id", "user_id", "artist_id", "user_gender", "context_type", "platform_name",
"platform_family", "listen_type", "is_listened")
data.full[, (temp) := lapply(.SD, factor), .SDcols = temp]
# converting timestamps
data.full[, release_date := as.Date(as.character(data.full$release_date), "%Y%m%d")]
data.full[, ts_listen := anytime(data.full$ts_listen, asUTC = T)]
# loading libraries
library(pacman)
pacman::p_load("anytime","data.table")
# Order data by user_id and ts_listen
# Using set* functions is faster
setorder(data.full, user_id, ts_listen)
#dt <- dt[order(ts_listen),.SD, by=user_id]
data.full[,time_lag:=c(NA, difftime(tail(ts_listen,-1), head(ts_listen,-1), units = "mins")), by = user_id]
data.full[is.na(time_lag), time_lag := 0]
#let's look at the most typical time lags
#summary(data.full$time_lag)
#let's take more than 30 mins as a start for a new session
#dt[,session_id := seq_along(time_lag), by = time_lag < 20]
data.full[, session_id := cumsum(time_lag>20)+1, by = user_id]
# Count the absolute position of the song in the session
data.full[, song_session_position := 1:.N, by = session_id]
# Find the index of the song in the flow
temp <- data.full[, list(listen_type = listen_type, session_id)]
temp[, flow_lag := shift(listen_type, fill = 0), by=session_id]
temp[, first_flow := as.numeric(listen_type == 1 & flow_lag == 0)]
#data.full[listen_type == "1", flow_position := cumsum(listen_type == "1" & shift(listen_type, fill = "0") == "0"), by = session_id]
data.full[, first_flow := temp$first_flow]
# Compute difference between the release date and listening date (number of days)
# NAs: release_date later than 2018; ts_listen before 2010 => substituted by mean values
# There are still 29,091 cases with time_diff < 0
data.full[, time_diff := as.numeric(as.Date(ts_listen) - release_date)]
data.full[ts_listen    < "2010-01-01", time_diff := NA]
data.full[release_date > "2018-01-01", time_diff := NA]
data.full[is.na(time_diff), time_diff := mean(data.full$time_diff, na.rm = T)]
#summary(data.full$time_diff)
# Create a factor variable for the hour of the day when the song is played
data.full[, hours := as.factor(format(as.POSIXct(data.full$ts_listen, format = "%H:%M:%S"),"%H"))]
# Create a lagged is_listened (for the previous song)
data.full[, is_listened_lag :=  shift(.SD), by = user_id, .SDcols = "is_listened"]
data.full[is.na(is_listened_lag), is_listened_lag := "none"]
data.full[song_session_position == 1, is_listened_lag :=  "none"]
tail(data.full[data.full$user_id == 2, c("user_id", "ts_listen", "is_listened", "is_listened_lag", "song_session_position")])
data.full <- as.data.frame(data.full)
tail(data.full[data.full$user_id == 2, c("user_id", "ts_listen", "is_listened", "is_listened_lag", "song_session_position")])
summary(data.full$is_listened_lag)
###################################
#                                 #
#             SETTINGS            #
#                                 #
###################################
# clearing the memory
rm(list = ls())
# setting work directory
work.folder <- "/Users/Kozodoi/Documents/Competitions/DSG_2017"
setwd(work.folder)
# setting inner folders
code.folder <- "codes"
data.folder <- "data"
func.folder <- "functions"
subm.folder <- "submissions"
# loading libraries
if(require(pacman)==FALSE) install.packages("pacman")
library(pacman)
p_load(data.table, anytime, randomForest, AUC, caret, beepr, xgboost)
# loading functions
source(file.path(code.folder, "code_0_helper_functions.R"))
###################################
#                                 #
#         DATA PREPARATION        #
#                                 #
###################################
########## 1. LOADING THE DATA
# loading training data
data.train <- fread(file.path(data.folder, "tr.csv"), sep = ",", dec = ".", header = T)
data.test  <- fread(file.path(data.folder, "ts.csv"), sep = ",", dec = ".", header = T)
# merging data sets
data.test$dataset  <- "test"
data.train$dataset <- "train"
data.full <- rbind(data.train, data.test)
setkey(data.full, user_id, media_id)
########## 2. CONVERTING VARIABLES
# converting factors
temp <- c("genre_id", "media_id", "album_id", "user_id", "artist_id", "user_gender", "context_type", "platform_name",
"platform_family", "listen_type", "is_listened")
data.full[, (temp) := lapply(.SD, factor), .SDcols = temp]
###################################
#                                 #
#             SETTINGS            #
#                                 #
###################################
# clearing the memory
rm(list = ls())
# setting work directory
work.folder <- "/Users/Kozodoi/Documents/Competitions/DSG_2017"
setwd(work.folder)
# setting inner folders
code.folder <- "codes"
data.folder <- "data"
func.folder <- "functions"
subm.folder <- "submissions"
# loading libraries
if(require(pacman)==FALSE) install.packages("pacman")
library(pacman)
p_load(data.table, anytime, randomForest, AUC, caret, beepr, xgboost)
# loading functions
source(file.path(code.folder, "code_0_helper_functions.R"))
###################################
#                                 #
#         DATA PREPARATION        #
#                                 #
###################################
########## 1. LOADING THE DATA
# loading training data
data.train <- fread(file.path(data.folder, "tr.csv"), sep = ",", dec = ".", header = T)
data.test  <- fread(file.path(data.folder, "ts.csv"), sep = ",", dec = ".", header = T)
# merging data sets
data.test$dataset  <- "test"
data.train$dataset <- "train"
data.full <- rbind(data.train, data.test)
setkey(data.full, user_id, media_id)
########## 2. CONVERTING VARIABLES
# converting factors
temp <- c("genre_id", "media_id", "album_id", "user_id", "artist_id", "user_gender", "context_type", "platform_name",
"platform_family", "listen_type", "is_listened")
data.full[, (temp) := lapply(.SD, factor), .SDcols = temp]
# converting timestamps
data.full[, release_date := as.Date(as.character(data.full$release_date), "%Y%m%d")]
data.full[, ts_listen := anytime(data.full$ts_listen, asUTC = T)]
########## 3. CREATING FEATURES
### Add naive skip ratios as features
source(file.path(code.folder, "code_2_features_naive_ratios.R"))
### Add total plays and skips as features
#source(file.path(code.folder, "code_2_features_total_plays.R"))
### Add time-related variables
source(file.path(code.folder, "code_2_features_time_related.R"))
########## 4. DATA PARTITIONING
# converting and partitioning
data.full <- as.data.frame(data.full)
data.train <- data.full[data.full$dataset == "train", ]
data.test  <- data.full[data.full$dataset == "test",  ]
rm(list = "data.full")
# sorting the testing data
data.test <- data.test[order(data.test$row_index), ]
###################################
#                                 #
#      MODELING FOR VALIDATION    #
#                                 #
###################################
# model equation
equation <- as.formula(is_listened ~ user_ratio_flow + context_type + platform_name)
# training XGB model
xg.grid  <- expand.grid(nrounds = 500, lambda = 1, alpha = 1, eta = 0.3)
tr.grid  <- trainControl(method = "none")
xg.model <- train(equation, data = data.train, method = "xgbLinear", trControl = tr.grid, tuneGrid = xg.grid)
xg.model
xg.pred <- predict(xg.model, newdata = data.test, type = "prob")[, "1"]
real <- data.test$is_listened
auc(roc(xg.pred, real))
xg <- data.frame(row_index = data.test$row_index, is_listened = xg.pred)
beep(2)
equation <- as.formula(is_listened ~ user_ratio_flow + context_type + is_listened_lag)
xg.grid  <- expand.grid(nrounds = 500, lambda = 1, alpha = 1, eta = 0.3)
xg.model <- train(equation, data = data.train, method = "xgbLinear", trControl = tr.grid, tuneGrid = xg.grid)
xg.model
xg.pred <- predict(xg.model, newdata = data.test, type = "prob")[, "1"]
real <- data.test$is_listened
auc(roc(xg.pred, real))
beep(2)
xg <- data.frame(row_index = data.test$row_index, is_listened = xg.pred)
write.table(xg, file = file.path("pred_valid", "xg_ratio_lag_context.csv"), quote = F, sep = ",", dec = ".")
###################################
#                                 #
#             SETTINGS            #
#                                 #
###################################
# clearing the memory
rm(list = ls())
# setting work directory
work.folder <- "/Users/Kozodoi/Documents/Competitions/DSG_2017"
setwd(work.folder)
# setting inner folders
code.folder <- "codes"
data.folder <- "data"
func.folder <- "functions"
subm.folder <- "submissions"
# loading libraries
if(require(pacman)==FALSE) install.packages("pacman")
library(pacman)
p_load(data.table, AUC, anytime, beepr, compiler)
# loading functions
source(file.path(code.folder, "code_0_helper_functions.R"))
###################################
#                                 #
#       1. VALIDATION DATA        #
#                                 #
###################################
###################################
#                                 #
#       1.1. DATA PREPARATION     #
#                                 #
###################################
# loading training data
data.train <- fread(file.path(data.folder, "tr.csv"), sep = ",", dec = ".", header = T)
data.test  <- fread(file.path(data.folder, "ts.csv"), sep = ",", dec = ".", header = T)
# merging data sets
data.test$dataset  <- "test"
data.train$dataset <- "train"
data.full <- rbind(data.train, data.test)
setkey(data.full, user_id, media_id)
# converting and partitioning
data.full <- as.data.frame(data.full)
data.train <- data.full[data.full$dataset == "train", ]
data.test  <- data.full[data.full$dataset == "test",  ]
rm(list = c("data.full", "data.train"))
# sorting the testing data
data.test$row_index <- as.numeric(as.character(data.test$row_index))
data.test <- data.test[order(data.test$row_index), ]
###################################
#                                 #
#     1.2. LOADING PREDICTIONS    #
#                                 #
###################################
# getting the list of files
file.list <- list.files("pred_valid")
preds <- list()
# loading all predictions
for (i in 1:length(file.list)) {
print(file.path("Loading ", file.list[i]))
preds[[i]] <- read.csv2(file.path("pred_valid", file.list[i]), sep = ",", dec = ".", header = T)
preds[[i]]$row_index <- as.numeric(as.character(preds[[i]]$row_index))
preds[[i]] <- preds[[i]][order(preds[[i]]$row_index), ]
}
# creating preddiction matrix
pred.matrix <- data.frame(row_index = data.test$row_index)
# merging all predicctions
for (i in 1:nrow(summary(preds))) {
pred.matrix <- cbind(pred.matrix, preds[[i]]$is_listened)
}
# assigning colnames
pred.matrix <- pred.matrix[, 2:ncol(pred.matrix)]
colnames(pred.matrix) <- file.list
# extracting real values
real <- as.factor(data.test$is_listened)
# droping weak classifiers
#aucs <- apply(pred.matrix, 2, function(x) auc(roc(x, real)))
#good <- names(aucs)[aucs >= 0.8]
#pred.matrix <- pred.matrix[, colnames(pred.matrix) %in% good]
# extracting number of models
k <- ncol(pred.matrix)
# mean and median predictions
pred.matrix$mean   <- apply(pred.matrix[,1:k], 1, mean)
pred.matrix$median <- apply(pred.matrix[,1:k], 1, median)
# ensemble selection
es.weights <- ES(X = pred.matrix[,1:k],  Y = real, iter = 100)
pred.matrix$es <- apply(pred.matrix[,1:k], 1, function(x) sum(x*es.weights))
# bagged ensemble selection
#bes.weights <- BES(X = pred.matrix[,1:k], Y = real, iter = 100, bags = 10, p = 0.5)
#pred.matrix$bag_es <- apply(pred.matrix[,1:k], 1, function(x) sum(x*bes.weights))
# computing AUC
apply(pred.matrix, 2, function(x) auc(roc(x, real)))
