print(i)
}
foreach(i = 1:10000) %dopar% {
print(i)
}
proc.time()
t <- proc.time()
foreach(i = 1:10000) %dopar% {
print(i)
}
proc.time() - t
t <- proc.time()
foreach(i = 1:10000) %do% {
print(i)
}
proc.time() - t
t <- proc.time()
foreach(i = 1:10000) %do% {
print(i)
}
x <- proc.time() - t
t <- proc.time()
foreach(i = 1:10000) %dopar% {
print(i)
}
x1 <- proc.time() - t
x
x1
cores <- detectCores() - 2
cl <- makeCluster(cores)
registerDoParallel(cl)
t <- proc.time()
foreach(i = 1:100000) %dopar% {
print(i)
}
xpar <- proc.time() - t
t <- proc.time()
foreach(i = 1:100000) %do% {
print(i)
}
x <- proc.time() - t
xpar
x
rm(list = ls())
library(doParallel)
library(foreach)
cores <- detectCores() - 2
cl <- makeCluster(cores)
registerDoParallel(cl)
t <- proc.time()
foreach(i = 1:100000) %dopar% {
print(i)
}
xpar <- proc.time() - t
t <- proc.time()
foreach(i = 1:100000) %do% {
print(i)
}
xdo <- proc.time() - t
t <- proc.time()
for (i in 1:100000) {
print(i)
}
x <- proc.time() - t
xpar
xdo
x
rm(list = ls())
###################################
#                                 #
#             SETTINGS            #
#                                 #
###################################
# clearing the memory
rm(list = ls())
# setting work directory
work.folder <- "/Users/Kozodoi/Documents/Competitions/DSG_2017"
setwd(work.folder)
# setting inner folders
code.folder <- "codes"
data.folder <- "data"
func.folder <- "functions"
subm.folder <- "submissions"
# loading libraries
if(require(pacman)==FALSE) install.packages("pacman")
library(pacman)
p_load(data.table, AUC, anytime, beepr, compiler)
# loading functions
source(file.path(code.folder, "code_0_helper_functions.R"))
###################################
#                                 #
#        1. DATA PREPARATION      #
#                                 #
###################################
# loading data
data.full <- read.csv2(file.path(data.folder, "data_flow.csv"), sep = ",", dec = ".", header = T)
# converting and partitioning
data.test  <- data.full[data.full$dataset == "test",  ]
data.unknown  <- data.full[data.full$dataset == "unknown",  ]
rm(list = c("data.full"))
data.test$row_index <- as.numeric(as.character(data.test$row_index))
rm(list = ls())
###################################
#                                 #
#             SETTINGS            #
#                                 #
###################################
# clearing the memory
rm(list = ls())
# setting work directory
# work.folder <- "N:/DSG2017/DSG_2017/"
work.folder <- "/Users/Kozodoi/Documents/Competitions/DSG_2017"
setwd(work.folder)
# setting inner folders
code.folder <- "codes"
data.folder <- "data"
func.folder <- "functions"
subm.folder <- "submissions"
# loading libraries
if(require(pacman)==FALSE) install.packages("pacman")
library(pacman)
p_load(data.table, anytime)
# loading functions
source(file.path(code.folder, "code_0_helper_functions.R"))
###################################
#                                 #
#         DATA PREPARATION        #
#                                 #
###################################
########## 1. LOADING THE DATA ####
# loading training data
data.train <- fread(file.path(data.folder, "train.csv"), sep = ",", dec = ".", header = T)
# loading testing data
data.test <- fread(file.path(data.folder, "test.csv"), sep = ",", dec = ".", header = T)
# merging data sets
data.test$is_listened <- NA
data.train$sample_id  <- NA
data.test$dataset <- "unknown"
data.train$dataset <- "train"
data.full <- rbind(data.train, data.test)
setkey(data.full, user_id, media_id)
rm(list = c("data.test",  "data.train"))
api.data <- read.delim(file.path(data.folder, "api_final.txt"), sep = ",", dec = ".")
summary(api.data)
summary(data.full$media_id)
summary(data.full$album_id)
colnames(api.data)
colnames(api.data)["track_id"]
colnames(api.data)[1] <- "media_id"
?merge
api.data <- as.data.table(read.delim(file.path(data.folder, "api_final.txt"), sep = ",", dec = "."))
head(data.full)
### add time-related variables
source(file.path(code.folder, "code_2_features_time_related.R"))
rm(list = "temp")
###################################
#                                 #
#             SETTINGS            #
#                                 #
###################################
# clearing the memory
rm(list = ls())
# setting work directory
# work.folder <- "N:/DSG2017/DSG_2017/"
work.folder <- "/Users/Kozodoi/Documents/Competitions/DSG_2017"
setwd(work.folder)
# setting inner folders
code.folder <- "codes"
data.folder <- "data"
func.folder <- "functions"
subm.folder <- "submissions"
# loading libraries
if(require(pacman)==FALSE) install.packages("pacman")
library(pacman)
p_load(data.table, anytime)
# loading functions
source(file.path(code.folder, "code_0_helper_functions.R"))
###################################
#                                 #
#         DATA PREPARATION        #
#                                 #
###################################
########## 1. LOADING THE DATA ####
# loading training data
data.train <- fread(file.path(data.folder, "train.csv"), sep = ",", dec = ".", header = T)
# loading testing data
data.test <- fread(file.path(data.folder, "test.csv"), sep = ",", dec = ".", header = T)
# merging data sets
data.test$is_listened <- NA
data.train$sample_id  <- NA
data.test$dataset <- "unknown"
data.train$dataset <- "train"
data.full <- rbind(data.train, data.test)
setkey(data.full, user_id, media_id)
rm(list = c("data.test",  "data.train"))
########## 2. CONVERTING VARIABLES ####
# converting factors
#temp <- c("genre_id", "media_id", "album_id", "user_id", "artist_id", "context_type", "platform_name", "platform_family")
#data.full[, (temp) := lapply(.SD, factor), .SDcols = temp]
# converting timestamps
data.full[, release_date := as.Date(as.character(data.full$release_date), "%Y%m%d")]
data.full[, ts_listen := anytime(data.full$ts_listen, asUTC = T)]
# loading libraries
library(pacman)
pacman::p_load("anytime","data.table", "lubridate")
# Order data by user_id and ts_listen
# Using set* functions is faster
setorder(data.full, user_id, ts_listen)
#dt <- dt[order(ts_listen),.SD, by=user_id]
data.full[,time_lag:=c(0, difftime(tail(ts_listen,-1), head(ts_listen,-1), units = "mins")), by = user_id]
#let's take more than 20 mins as a start for a new session
#dt[,session_id := seq_along(time_lag), by = time_lag < 20]
data.full[, session_id := cumsum(time_lag>20)+1, by = user_id]
# Count the absolute position of the song in the session
data.full[, song_session_position := 1:.N, by = c("user_id", "session_id")]
# Find the index of the song in the flow
temp <- data.full[, list(listen_type = listen_type, user_id, session_id)]
temp[, flow_lag := shift(listen_type, fill = 0), by = c("user_id", "session_id")]
temp[, first_flow := as.numeric(listen_type == 1 & flow_lag == 0)]
#data.full[listen_type == "1", flow_position := cumsum(listen_type == "1" & shift(listen_type, fill = "0") == "0"), by = session_id]
data.full[, first_flow := temp$first_flow]
# Compute difference between the release date and listening date (number of days)
# NAs: release_date later than 2018; ts_listen before 2010 => substituted by mean values
# There are still 29,091 cases with time_diff < 0
data.full[, time_diff_release_listen := as.numeric(as.Date(ts_listen) - release_date)]
data.full[ts_listen    < "2010-01-01", time_diff_release_listen := NA]
data.full[release_date > as.Date("2018-01-01"), time_diff_release_listen := NA]
temp.mean <- mean(data.full$time_diff_release_listen, na.rm = T)
data.full[is.na(time_diff_release_listen), time_diff_release_listen := temp.mean]
#summary(data.full$time_diff)
# Create a factor variable for the hour of the day when the song is played
data.full[, hour_of_day := factor(cut(hour(ts_listen), 8, labels = FALSE))]
# Weekday
data.full[, weekday := factor(weekdays(ts_listen, abbreviate = TRUE))]
# Release year
data.full[, release_year := year(release_date)]
# Create a lagged is_listened (for the previous song)
data.full[, c("is_listened_lag1", "is_listened_lag2") :=  shift(is_listened, 1:2), by = user_id]
data.full[, c("user_skip_ratio_last5") := rowMeans(mapply(cbind, shift(is_listened, 1:5)), na.rm = TRUE), by = user_id]
#data.full[, is_listened_lag :=  as.numeric(is_listened_lag)-1]
data.full[is.na(is_listened_lag1), is_listened_lag1 := 0]
data.full[is.na(is_listened_lag2), is_listened_lag2 := 0]
data.full[song_session_position == 1, c("is_listened_lag1", "is_listened_lag2") := 0] # user to be := 'none', but that changes the column to character
data.full[is.na(user_skip_ratio_last5)|is.nan(user_skip_ratio_last5), user_skip_ratio_last5 := 0.5]
# Create features capturing difference of the song to the last songs
data.full[, genre_equal_last_song := as.numeric(genre_id == shift(genre_id, fill = 0)), by = user_id]
data.full[, artist_equal_last_song := as.numeric(artist_id == shift(artist_id, fill = 0)), by = user_id]
data.full[, album_equal_last_song := as.numeric(album_id == shift(album_id, fill = 0)), by = user_id]
# # easier to load, however use rbind, after ordering dt <- dt[order(ts_listen),.SD, by=user_id]
# save(session_id, file = file.path(data.folder, "session_id_vector.Rda"))
rm(list = "temp")
api.data <- as.data.table(read.delim(file.path(data.folder, "api_final.txt"), sep = ",", dec = "."))
colnames(api.data)[1] <- "media_id"
head(api.data)
kkk <- merge(data.full, api.data, by = c("media_id", "album_id"), all.x = T, all.y = F, sort = F)
kkk <- merge(data.full, api.data, by = c("media_id", "album_id"), all = F, sort = F)
kkk <- merge(data.full, api.data, by = c("media_id", "album_id"), all.x = F, all.y = F, sort = F)
kkk <- merge(data.full, api.data, by = c("media_id", "album_id"), all.x = T, all.y = F, sort = F)
head(kk)
head(kkk)
head(data.full)
tail(kkk)
dim(kkk)
kkk <- as.data.frame(kkk)
head(kkk)
head(data.full)
dim(data.full)
###################################
#                                 #
#             SETTINGS            #
#                                 #
###################################
# clearing the memory
rm(list = ls())
# setting work directory
# work.folder <- "N:/DSG2017/DSG_2017/"
#work.folder <- "/Users/Kozodoi/Documents/Competitions/DSG_2017"
#setwd(work.folder)
# setting inner folders
code.folder <- "codes"
data.folder <- "data"
func.folder <- "functions"
subm.folder <- "submissions"
# loading libraries
if(require(pacman)==FALSE) install.packages("pacman")
library(pacman)
p_load(data.table, anytime)
# loading functions
source(file.path(code.folder, "code_0_helper_functions.R"))
###################################
#                                 #
#         DATA PREPARATION        #
#                                 #
###################################
########## 1. LOADING THE DATA ####
# loading training data
data.train <- fread(file.path(data.folder, "train.csv"), sep = ",", dec = ".", header = T)
# loading testing data
data.test <- fread(file.path(data.folder, "test.csv"), sep = ",", dec = ".", header = T)
# merging data sets
data.test$is_listened <- NA
data.train$sample_id  <- NA
data.test$dataset <- "unknown"
data.train$dataset <- "train"
data.full <- rbind(data.train, data.test)
setkey(data.full, user_id, media_id)
rm(list = c("data.test",  "data.train"))
api.data <- fread(file.path(data.folder, "api_final.txt"), sep = ",", dec = ".", header = T)
api.data[fans == -1, fans := 0]
data.full <- merge(data.full, api.data[,.(track_id, rank,bpm,position,lyrics_explicit,gain,fans)], by.x = "media_id", by.y = "track_id")
########## 2. CONVERTING VARIABLES ####
# converting factors
#temp <- c("genre_id", "media_id", "album_id", "user_id", "artist_id", "context_type", "platform_name", "platform_family")
#data.full[, (temp) := lapply(.SD, factor), .SDcols = temp]
# converting timestamps
data.full[, release_date := as.Date(as.character(data.full$release_date), "%Y%m%d")]
data.full[, ts_listen := anytime(data.full$ts_listen, asUTC = T)]
########## 3. CREATING FEATURES ON FULL DATA ####
### add data from json file, info on song name, album name, artist name
#if(file.exists(file.path(data.folder, "info_json.rds"))){
#  extra_info <- readRDS(file.path(data.folder, "info_json.rds"))
#}else{
#  source(file.path(code.folder,"code_2_features_json_file.R"))
#  saveRDS(extra_info, file = file.path(data.folder, "info_json.Rds"))
#}
#data.full <- merge(data.full, extra_info, by = "media_id", all.x = TRUE)
### add time-related variables
source(file.path(code.folder, "code_2_features_time_related.R"))
rm(list = "temp")
########## 4. DATA PARTITIONING
# Extract last 10 observations for each user, if possible
# Will move rare users completely to the test set
#data.full[data.full[dataset == "train", list(index = head(.I, 10)), by = user_id]$index, dataset := "test"]
# testing set: last 3 first_flow songs per user (if available)
# training set: all remaining songs
data.full[first_flow == 1 & dataset == "train", dataset := "test_candidate"] # here: 169,498 cases in testing
data.full[data.full[dataset == "test_candidate", list(index = tail(.I, 3)), by = user_id]$index, dataset := "test"] # here: 39,821 cases in testing
data.full[dataset == "test_candidate", dataset := "train"]
table(data.full$dataset)
########## 5. CREATING FEATURES ON PARTITIONED DATA
### Compute total plays and skips as features
source(file.path(code.folder, "code_2_features_total_plays.R"))
rm(list = "data.train")
### Compute naive skip ratios as features
source(file.path(code.folder, "code_2_features_naive_ratios.R"))
rm(list = "data.train")
########## 6. EXPORTING DATA
# Drop non-FLow songs from the training data [OPTIONAL]
data.full <- data.full[dataset != "train" | listen_type == 1, ]
# Make nice IDs for embedding
# Note that rare IDs are replaced and all original ID info dropped
source(file.path(func.folder, "createEmbeddingID.R"))
trainIdx <- which(data.full$dataset == "train")
data.full[, user_id := createEmbeddingID(user_id, trainIdx = trainIdx)]
idCols <- c("user_id", "artist_id", "media_id", "genre_id", "album_id", "context_type")
data.full[, (idCols) := lapply(.SD, createEmbeddingID, trainIdx = trainIdx), .SDcols = idCols]
# Remove everything not needed for estimation
data.full[, c("ts_listen", "release_date", "time_lag", "album_id") := NULL]
# Transform factor to dummy
factorCols <- c("platform_name", "platform_family", "hour_of_day", "weekday")
data.full <- cbind(data.full, model.matrix(~.-1, data = data.full[, (factorCols), with=FALSE]))
data.full[, (factorCols) := NULL]
# saving the data: data_full.csv for all songs, data_flow.csv for flow songs
#write.table(data.full, file.path(data.folder, "data_full.csv"), sep = ",", dec = ".", quote = F)
write.table(data.full, file.path(data.folder, "data_flow.csv"), sep = ",", dec = ".", quote = F)
head(data.full)
cor(data.full$is_listened, data.full$fans)
?cor
cor(data.full$is_listened, data.full$fans, "pairwise.complete.obs")
cor(data.full$is_listened, data.full$is_listened_lag1, "pairwise.complete.obs")
cor(data.full$is_listened, data.full$is_listened_lag2, "pairwise.complete.obs")
cor(data.full$is_listened, data.full$user_ratio_flow, "pairwise.complete.obs")
cor(data.full$is_listened, data.full$user_ratio_full, "pairwise.complete.obs")
cor(data.full$is_listened, data.full$user_skip_ratio_last5, "pairwise.complete.obs")
cor(data.full$is_listened, data.full$gain, "pairwise.complete.obs")
cor(data.full$is_listened, data.full$rank, "pairwise.complete.obs")
cor(data.full$is_listened, data.full$lyrics_explicit, "pairwise.complete.obs")
cor(data.full$is_listened, data.full$user_gender, "pairwise.complete.obs")
cor(data.full$is_listened, data.full$user_age, "pairwise.complete.obs")
cor(data.full$is_listened, data.full$media_duration, "pairwise.complete.obs")
summary(data.full)
cor(data.full$is_listened, data.full$first_flow, "pairwise.complete.obs")
cor(data.full$is_listened, data.full$song_session_position, "pairwise.complete.obs")
###################################
#                                 #
#             SETTINGS            #
#                                 #
###################################
# clearing the memory
rm(list = ls())
# setting work directory
# work.folder <- "N:/DSG2017/DSG_2017/"
#work.folder <- "/Users/Kozodoi/Documents/Competitions/DSG_2017"
#setwd(work.folder)
# setting inner folders
code.folder <- "codes"
data.folder <- "data"
func.folder <- "functions"
subm.folder <- "submissions"
# loading libraries
if(require(pacman)==FALSE) install.packages("pacman")
library(pacman)
p_load(data.table, anytime)
# loading functions
source(file.path(code.folder, "code_0_helper_functions.R"))
###################################
#                                 #
#         DATA PREPARATION        #
#                                 #
###################################
########## 1. LOADING THE DATA ####
# loading training data
data.train <- fread(file.path(data.folder, "train.csv"), sep = ",", dec = ".", header = T)
###################################
#                                 #
#             SETTINGS            #
#                                 #
###################################
# clearing the memory
rm(list = ls())
# setting work directory
# work.folder <- "N:/DSG2017/DSG_2017/"
#work.folder <- "/Users/Kozodoi/Documents/Competitions/DSG_2017"
#setwd(work.folder)
# setting inner folders
code.folder <- "codes"
data.folder <- "data"
func.folder <- "functions"
subm.folder <- "submissions"
# loading libraries
if(require(pacman)==FALSE) install.packages("pacman")
library(pacman)
p_load(data.table, anytime)
# loading functions
source(file.path(code.folder, "code_0_helper_functions.R"))
###################################
#                                 #
#         DATA PREPARATION        #
#                                 #
###################################
########## 1. LOADING THE DATA ####
# loading training data
data.train <- fread(file.path(data.folder, "train.csv"), sep = ",", dec = ".", header = T)
# loading testing data
data.test <- fread(file.path(data.folder, "test.csv"), sep = ",", dec = ".", header = T)
# merging data sets
data.test$is_listened <- NA
data.train$sample_id  <- NA
data.test$dataset <- "unknown"
data.train$dataset <- "train"
data.full <- rbind(data.train, data.test)
setkey(data.full, user_id, media_id)
rm(list = c("data.test",  "data.train"))
api.data <- fread(file.path(data.folder, "api_final.txt"), sep = ",", dec = ".", header = T)
api.data[fans == -1, fans := 0]
data.full <- merge(data.full, api.data[,.(track_id, rank,bpm,position,lyrics_explicit,gain,fans)], by.x = "media_id", by.y = "track_id")
########## 2. CONVERTING VARIABLES ####
# converting factors
#temp <- c("genre_id", "media_id", "album_id", "user_id", "artist_id", "context_type", "platform_name", "platform_family")
#data.full[, (temp) := lapply(.SD, factor), .SDcols = temp]
# converting timestamps
data.full[, release_date := as.Date(as.character(data.full$release_date), "%Y%m%d")]
data.full[, ts_listen := anytime(data.full$ts_listen, asUTC = T)]
########## 3. CREATING FEATURES ON FULL DATA ####
### add data from json file, info on song name, album name, artist name
#if(file.exists(file.path(data.folder, "info_json.rds"))){
#  extra_info <- readRDS(file.path(data.folder, "info_json.rds"))
#}else{
#  source(file.path(code.folder,"code_2_features_json_file.R"))
#  saveRDS(extra_info, file = file.path(data.folder, "info_json.Rds"))
#}
#data.full <- merge(data.full, extra_info, by = "media_id", all.x = TRUE)
### add time-related variables
source(file.path(code.folder, "code_2_features_time_related.R"))
rm(list = "temp")
########## 4. DATA PARTITIONING
# Extract last 10 observations for each user, if possible
# Will move rare users completely to the test set
#data.full[data.full[dataset == "train", list(index = head(.I, 10)), by = user_id]$index, dataset := "test"]
# testing set: last 3 first_flow songs per user (if available)
# training set: all remaining songs
data.full[first_flow == 1 & dataset == "train", dataset := "test_candidate"] # here: 169,498 cases in testing
data.full[data.full[dataset == "test_candidate", list(index = tail(.I, 3)), by = user_id]$index, dataset := "test"] # here: 39,821 cases in testing
data.full[dataset == "test_candidate", dataset := "train"]
table(data.full$dataset)
########## 5. CREATING FEATURES ON PARTITIONED DATA
### Compute total plays and skips as features
source(file.path(code.folder, "code_2_features_total_plays.R"))
rm(list = "data.train")
### Compute naive skip ratios as features
source(file.path(code.folder, "code_2_features_naive_ratios.R"))
rm(list = "data.train")
########## 6. EXPORTING DATA
# Drop non-FLow songs from the training data [OPTIONAL]
#data.full <- data.full[dataset != "train" | listen_type == 1, ]
# Make nice IDs for embedding
# Note that rare IDs are replaced and all original ID info dropped
source(file.path(func.folder, "createEmbeddingID.R"))
trainIdx <- which(data.full$dataset == "train")
data.full[, user_id := createEmbeddingID(user_id, trainIdx = trainIdx)]
idCols <- c("user_id", "artist_id", "media_id", "genre_id", "album_id", "context_type")
data.full[, (idCols) := lapply(.SD, createEmbeddingID, trainIdx = trainIdx), .SDcols = idCols]
# Remove everything not needed for estimation
data.full[, c("ts_listen", "release_date", "time_lag", "album_id") := NULL]
# Transform factor to dummy
factorCols <- c("platform_name", "platform_family", "hour_of_day", "weekday")
data.full <- cbind(data.full, model.matrix(~.-1, data = data.full[, (factorCols), with=FALSE]))
data.full[, (factorCols) := NULL]
# saving the data: data_full.csv for all songs, data_flow.csv for flow songs
write.table(data.full, file.path(data.folder, "data_full.csv"), sep = ",", dec = ".", quote = F)
#write.table(data.full, file.path(data.folder, "data_flow.csv"), sep = ",", dec = ".", quote = F)
rm(list = ls())
