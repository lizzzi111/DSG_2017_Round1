install.packages("foreach")
install.packages("doParallel")
library(doParallel)
library(foreach)
foreach(i = 1:10) %do% {
print(i)
}
foreach(i = 1:1000) %do% {
print(i)
}
detectCores()
cl <- makeCluster(detectCores() - 2)
cores <- detectCores() - 2
cl <- makeCluster(cores)
registerDoParallel(cl)
foreach(i = 1:10000) %do% {
print(i)
}
foreach(i = 1:10000) %dopar% {
print(i)
}
proc.time()
t <- proc.time()
foreach(i = 1:10000) %dopar% {
print(i)
}
proc.time() - t
t <- proc.time()
foreach(i = 1:10000) %do% {
print(i)
}
proc.time() - t
t <- proc.time()
foreach(i = 1:10000) %do% {
print(i)
}
x <- proc.time() - t
t <- proc.time()
foreach(i = 1:10000) %dopar% {
print(i)
}
x1 <- proc.time() - t
x
x1
cores <- detectCores() - 2
cl <- makeCluster(cores)
registerDoParallel(cl)
t <- proc.time()
foreach(i = 1:100000) %dopar% {
print(i)
}
xpar <- proc.time() - t
t <- proc.time()
foreach(i = 1:100000) %do% {
print(i)
}
x <- proc.time() - t
xpar
x
rm(list = ls())
library(doParallel)
library(foreach)
cores <- detectCores() - 2
cl <- makeCluster(cores)
registerDoParallel(cl)
t <- proc.time()
foreach(i = 1:100000) %dopar% {
print(i)
}
xpar <- proc.time() - t
t <- proc.time()
foreach(i = 1:100000) %do% {
print(i)
}
xdo <- proc.time() - t
t <- proc.time()
for (i in 1:100000) {
print(i)
}
x <- proc.time() - t
xpar
xdo
x
rm(list = ls())
###################################
#                                 #
#             SETTINGS            #
#                                 #
###################################
# clearing the memory
rm(list = ls())
# setting work directory
work.folder <- "/Users/Kozodoi/Documents/Competitions/DSG_2017"
setwd(work.folder)
# setting inner folders
code.folder <- "codes"
data.folder <- "data"
func.folder <- "functions"
subm.folder <- "submissions"
# loading libraries
if(require(pacman)==FALSE) install.packages("pacman")
library(pacman)
p_load(data.table, anytime, randomForest, AUC, caret, beepr, xgboost)
# loading functions
source(file.path(code.folder, "code_0_helper_functions.R"))
###################################
#                                 #
#         DATA PREPARATION        #
#                                 #
###################################
########## 1. LOADING THE DATA
# loading training data
data.train <- fread(file.path(data.folder, "tr.csv"), sep = ",", dec = ".", header = T)
data.test  <- fread(file.path(data.folder, "ts.csv"), sep = ",", dec = ".", header = T)
# merging data sets
data.test$dataset  <- "test"
data.train$dataset <- "train"
data.full <- rbind(data.train, data.test)
setkey(data.full, user_id, media_id)
########## 2. CONVERTING VARIABLES
# converting factors
temp <- c("genre_id", "media_id", "album_id", "user_id", "artist_id", "user_gender", "context_type", "platform_name",
"platform_family", "listen_type", "is_listened")
data.full[, (temp) := lapply(.SD, factor), .SDcols = temp]
# converting timestamps
data.full[, release_date := as.Date(as.character(data.full$release_date), "%Y%m%d")]
data.full[, ts_listen := anytime(data.full$ts_listen, asUTC = T)]
# subsetting
data.train <- data.full[dataset == 'train',]
# converting to numeric
data.train$is_listened <- as.numeric(data.train$is_listened)-1
##### COMPUTING VARIABLES
# computing historical play/skip ratios
message("Calculate ratios")
user.ratio.flow <- data.train[listen_type == "1", .(user_ratio_flow = mean(is_listened)), by = .(user_id)]
user.ratio.othr <- data.train[listen_type == "0", .(user_ratio_othr = mean(is_listened)), by = .(user_id)]
genre.ratio     <- data.train[, .(genre_ratio = mean(is_listened), count = .N),  by = .(user_id, genre_id)]
artist.ratio    <- data.train[, .(artist_ratio = mean(is_listened), count = .N), by = .(user_id, artist_id)]
song.ratio      <- data.train[, .(song_ratio = mean(is_listened), count = .N),   by = .(user_id, media_id)]
# keeping genre/artist/song data with at least 30 appearances
genre.ratio  <- genre.ratio[count   >= 30, ]
artist.ratio <- artist.ratio[count  >= 30, ]
song.ratio   <- song.ratio[count    >= 30, ]
genre.ratio  <- genre.ratio[, count  := NULL]
artist.ratio <- artist.ratio[, count := NULL]
song.ratio   <- song.ratio[, count   := NULL]
##### WRITING VALUES
# saving simple ratios
message("Merge ratio with full data")
data.full <- merge(data.full, user.ratio.flow, all.x = TRUE, sort = F, by = "user_id")
data.full <- merge(data.full, user.ratio.othr, all.x = TRUE, sort = F, by = "user_id")
data.full <- merge(data.full, genre.ratio,     all.x = TRUE, sort = F, by = c("user_id","genre_id"))
data.full <- merge(data.full, artist.ratio,    all.x = TRUE, sort = F, by = c("user_id", "artist_id"))
data.full <- merge(data.full, song.ratio,      all.x = TRUE, sort = F, by = c("user_id", "media_id"))
# displaying resulted ratios
#summary(data.full[, c("user_ratio", "genre_ratio", "artist_ratio", "song_ratio")])
#cor(data.full[, c("user_ratio", "genre_ratio", "artist_ratio", "song_ratio")], use = "complete")
# imputing NAs with user ratio
data.full[is.na(user_ratio_othr), user_ratio_othr := mean(data.train$is_listened)]
data.full[is.na(user_ratio_flow), user_ratio_flow := user_ratio_othr]
data.full[is.na(genre_ratio),  genre_ratio  := mean(data.train$is_listened)]
data.full[is.na(artist_ratio), artist_ratio := mean(data.train$is_listened)]
data.full[is.na(song_ratio),   song_ratio   := mean(data.train$is_listened)]
# loading libraries
library(pacman)
pacman::p_load("anytime","data.table")
# Order data by user_id and ts_listen
# Using set* functions is faster
setorder(data.full, user_id, ts_listen)
#dt <- dt[order(ts_listen),.SD, by=user_id]
data.full[,time_lag:=c(NA, difftime(tail(ts_listen,-1), head(ts_listen,-1), units = "mins")), by = user_id]
data.full[is.na(time_lag), time_lag := 0]
#let's look at the most typical time lags
#summary(data.full$time_lag)
#let's take more than 30 mins as a start for a new session
#dt[,session_id := seq_along(time_lag), by = time_lag < 20]
data.full[, session_id := cumsum(time_lag>20)+1, by = user_id]
# Count the absolute position of the song in the session
data.full[, song_session_position := 1:.N, by = session_id]
# Find the index of the song in the flow
temp <- data.full[, list(listen_type = listen_type, session_id)]
temp[, flow_lag := shift(listen_type, fill = 0), by=session_id]
temp[, first_flow := as.numeric(listen_type == 1 & flow_lag == 0)]
#data.full[listen_type == "1", flow_position := cumsum(listen_type == "1" & shift(listen_type, fill = "0") == "0"), by = session_id]
data.full[, first_flow := temp$first_flow]
# Compute difference between the release date and listening date (number of days)
# NAs: release_date later than 2018; ts_listen before 2010 => substituted by mean values
# There are still 29,091 cases with time_diff < 0
data.full[, time_diff := as.numeric(as.Date(ts_listen) - release_date)]
data.full[ts_listen    < "2010-01-01", time_diff := NA]
data.full[release_date > "2018-01-01", time_diff := NA]
data.full[is.na(time_diff), time_diff := mean(data.full$time_diff, na.rm = T)]
#summary(data.full$time_diff)
# Create a factor variable for the hour of the day when the song is played
data.full[, hours := as.factor(format(as.POSIXct(data.full$ts_listen, format = "%H:%M:%S"),"%H"))]
data.full[, is_listened_lag :=  shift(.SD), by = user_id, .SDcols = "is_listened"]
data.full[, is_listened_lag :=  as.numeric(is_listened_lag)-1]
data.full[is.na(is_listened_lag), is_listened_lag := user_ratio_flow]
summary(data.full)
